{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"},{"sourceId":1664376,"sourceType":"datasetVersion","datasetId":985270},{"sourceId":5181249,"sourceType":"datasetVersion","datasetId":3012199},{"sourceId":8108072,"sourceType":"datasetVersion","datasetId":4789213},{"sourceId":8319412,"sourceType":"datasetVersion","datasetId":4941521},{"sourceId":8478505,"sourceType":"datasetVersion","datasetId":5056677},{"sourceId":8605414,"sourceType":"datasetVersion","datasetId":5149186}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":72.272366,"end_time":"2024-05-27T08:24:12.863444","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-27T08:23:00.591078","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"087aee61943640ff866fad504d3bb8b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2412ab76a24d443693ab5c99798255d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3051ba21b6bb4960912b45a267d7954e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b524d1526854b07a9cbd17a164389ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3051ba21b6bb4960912b45a267d7954e","placeholder":"​","style":"IPY_MODEL_087aee61943640ff866fad504d3bb8b7","value":""}},"603297b6cf5a4516b17db45b449d8bcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee52a129532428f97b4ffa466195640","placeholder":"​","style":"IPY_MODEL_98758643ec6f4277946a0b2523b33a62","value":" 0/0 [00:00&lt;?, ?it/s]"}},"7de4c22f5bde4876bd7045b85b99ed48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b524d1526854b07a9cbd17a164389ac","IPY_MODEL_919bacdd323e48c4a80b2ef6b3bdc060","IPY_MODEL_603297b6cf5a4516b17db45b449d8bcd"],"layout":"IPY_MODEL_85db54c088da49578b1a07af47f9565e"}},"85db54c088da49578b1a07af47f9565e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919bacdd323e48c4a80b2ef6b3bdc060":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2412ab76a24d443693ab5c99798255d6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd98675913fb42bca53f7133abd10dae","value":0}},"98758643ec6f4277946a0b2523b33a62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aee52a129532428f97b4ffa466195640":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd98675913fb42bca53f7133abd10dae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\"> 1 | Installing Libraries </p>","metadata":{"papermill":{"duration":0.023488,"end_time":"2024-05-27T08:23:03.890039","exception":false,"start_time":"2024-05-27T08:23:03.866551","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n    !pip install /kaggle/input/onnxruntime/humanfriendly-10.0-py2.py3-none-any.whl --no-index --find-links /kaggle/input/onnxruntime\n    !pip install /kaggle/input/onnxruntime/coloredlogs-15.0.1-py2.py3-none-any.whl --no-index --find-links /kaggle/input/onnxruntime\n    !pip install /kaggle/input/onnxruntime/onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl --no-index --find-links /kaggle/input/onnxruntime","metadata":{"papermill":{"duration":47.930075,"end_time":"2024-05-27T08:23:51.84393","exception":false,"start_time":"2024-05-27T08:23:03.913855","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:56:27.764741Z","iopub.execute_input":"2024-06-09T06:56:27.765158Z","iopub.status.idle":"2024-06-09T06:57:15.528017Z","shell.execute_reply.started":"2024-06-09T06:56:27.765124Z","shell.execute_reply":"2024-06-09T06:57:15.526497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">2 | Importing Libraries </p>","metadata":{"papermill":{"duration":0.025691,"end_time":"2024-05-27T08:23:51.894478","exception":false,"start_time":"2024-05-27T08:23:51.868787","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport glob\nimport time\nimport shutil\nimport random\nimport ast\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport onnx\nimport onnxruntime as ort\nimport wandb\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom tqdm.notebook import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom torch.cuda import amp\nimport torch\nprint(f\"pytorch version is {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.cuda import amp\n\nisTrain = False\nname = 'bird2024exp1057'\n\nimport torchvision\nfrom torchvision.transforms import v2 as transforms\n\nimport librosa\nimport torchaudio\nimport torchaudio.transforms as audioT\n\nimport timm","metadata":{"papermill":{"duration":13.435679,"end_time":"2024-05-27T08:24:05.355498","exception":false,"start_time":"2024-05-27T08:23:51.919819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:57:32.315963Z","iopub.execute_input":"2024-06-09T06:57:32.316419Z","iopub.status.idle":"2024-06-09T06:57:43.230528Z","shell.execute_reply.started":"2024-06-09T06:57:32.316386Z","shell.execute_reply":"2024-06-09T06:57:43.228981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">3 | Configuration Class </p>\n\n","metadata":{"papermill":{"duration":0.026074,"end_time":"2024-05-27T08:24:05.406693","exception":false,"start_time":"2024-05-27T08:24:05.380619","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.024724,"end_time":"2024-05-27T08:24:05.457874","exception":false,"start_time":"2024-05-27T08:24:05.43315","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class config:\n    dir = \"/kaggle/input/birdclef-2024/\"\n\n\n    wave_path = \"original_waves/second_30/\"\n\n    model_name = 'tf_efficientnet_b0'\n\n    pool_type = 'avg'\n\n    \n    train_duration = 30 \n    slice_duration = 5 \n\n    test_duration = 5\n\n    train_drop_duration = 1\n    \n    # spectrogram parameters\n    sr = 32000\n    fmin = 20\n    fmax = 15000\n\n    n_mels = 128\n    n_fft = n_mels*8\n    size_x = 512\n    \n    hop_length = int(sr*slice_duration / size_x)\n    test_hop_length = int(sr*test_duration / size_x)\n    \n    bins_per_octave = 12\n\n    nfolds = 5\n    inference_folds = [4]\n    \n    enable_amp = True\n    train_batchsize = 32\n    valid_batchsize = 1\n\n    # loss_type = \"BCEWithLogitsLoss\"\n    loss_type = \"BCEFocalLoss\"\n\n    #调整学习率，变大，收敛快一点\n    lr = 2.0e-04 \n\n\n    optimizer='adan'\n    weight_decay = 1.0e-03  #更改过拟合2\n    es_patience =  5\n    deterministic = True\n    enable_amp = True\n\n    max_epoch = 9\n    aug_epoch = 7   #数据增强\n    \n\n    useSecondary =True\n    #置信度\n    secondary_label_value = 0.6\n    #决定是否对数据进行过采样。如果设置为 True，表明你打算增加少数类样本的数量，以此来减少类别不平衡的问题。\n    oversample =True\n    oversample_threthold = 5\n    \n    seed = 42\n\n    wandb = True\n\n    ###augmentation flags   音频增强参数设置\n    aug_noise            = 0.\n    aug_gain             = 0.0\n    aug_wave_pitchshift  = 0.0\n    aug_wave_shift       = 0.\n\n    aug_spec_xymasking   = 0.\n    aug_spec_coarsedrop  = 0.\n    aug_spec_hflip       = 0.\n\n    ##mixup param\n    aug_wave_mixup       = 1.0\n    aug_spec_mixup       = 0.1\n    aug_spec_mixup_prob  = 0.5 \n    alpha=0.96\n\n    smoothing_value      = 0.0\n    # spec_mix_mask_percent = 20\n    \ncfg = config()\n\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n\nprint(device)","metadata":{"papermill":{"duration":0.045294,"end_time":"2024-05-27T08:24:05.579365","exception":false,"start_time":"2024-05-27T08:24:05.534071","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:57:58.934838Z","iopub.execute_input":"2024-06-09T06:57:58.935282Z","iopub.status.idle":"2024-06-09T06:57:58.949432Z","shell.execute_reply.started":"2024-06-09T06:57:58.935248Z","shell.execute_reply":"2024-06-09T06:57:58.948287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">4 | Data Augmentation Pipeline For Training </p>","metadata":{"papermill":{"duration":0.024909,"end_time":"2024-05-27T08:24:05.629426","exception":false,"start_time":"2024-05-27T08:24:05.604517","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if isTrain== True:\n#多个数据增强操作\n    normal_augment = Compose([\n        OneOf([\n            Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n            GainTransition(min_gain_in_db=-24.0, max_gain_in_db=6.0,\n                           min_duration=0.2, max_duration=6.0,  p=1.0)\n        ], p=cfg.aug_gain),\n        \n        OneOf([\n            AddGaussianNoise(p=1),\n            AddColorNoise(p=1, min_snr_db=5, max_snr_db=20, min_f_decay=-3.01, max_f_decay=-3.01)\n        ],p=cfg.aug_noise),\n\n    \n        PitchShift(min_semitones=-1, max_semitones=1, p=cfg.aug_wave_pitchshift),\n        Shift(p=cfg.aug_wave_shift)\n    ])\n    alb_transform = [\n        albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n                                 mask_x_length=cfg.size_x//30, mask_y_length=cfg.n_mels//30,\n                                 fill_value=0, mask_fill_value=0, p=cfg.aug_spec_xymasking),\n        albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=cfg.aug_spec_coarsedrop),\n        albumentations.HorizontalFlip(p=cfg.aug_spec_hflip)    \n    ]\n    albumentations_augment = albumentations.Compose(alb_transform)","metadata":{"papermill":{"duration":0.041072,"end_time":"2024-05-27T08:24:05.746803","exception":false,"start_time":"2024-05-27T08:24:05.705731","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:03.577425Z","iopub.execute_input":"2024-06-09T06:58:03.578198Z","iopub.status.idle":"2024-06-09T06:58:03.588759Z","shell.execute_reply.started":"2024-06-09T06:58:03.578157Z","shell.execute_reply":"2024-06-09T06:58:03.587595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">5 |  Mixup Data Augmentation Function </p>\n","metadata":{"papermill":{"duration":0.024922,"end_time":"2024-05-27T08:24:05.797788","exception":false,"start_time":"2024-05-27T08:24:05.772866","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def mixup(data, targets, alpha, mode=\"same_wave\"):\n    \n    if mode == \"same_wave\":\n        data = torch.tensor(data)\n        indices = torch.randperm(data.size(0))\n        shuffled_data = data[indices]\n\n        lam = np.random.beta(alpha, alpha)\n        new_data = data * lam + shuffled_data * (1 - lam)\n        return new_data.numpy()\n     #保证数据以及标签都有泛化   \n    elif mode == \"other_wave\":\n        indices = torch.randperm(data.size(0))\n        shuffled_data = data[indices]\n        shuffled_targets = targets[indices]\n    \n        lam = np.random.beta(alpha, alpha)\n        new_data = data * lam + shuffled_data * (1 - lam)\n        new_targets = targets * lam + shuffled_targets * (1 - lam)\n    \n        return new_data, new_targets","metadata":{"papermill":{"duration":0.040647,"end_time":"2024-05-27T08:24:05.864611","exception":false,"start_time":"2024-05-27T08:24:05.823964","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:06.518177Z","iopub.execute_input":"2024-06-09T06:58:06.518619Z","iopub.status.idle":"2024-06-09T06:58:06.528057Z","shell.execute_reply.started":"2024-06-09T06:58:06.518585Z","shell.execute_reply":"2024-06-09T06:58:06.526729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">6 | Spectral Mixup Function</p>\n\n\n\n","metadata":{"papermill":{"duration":0.024581,"end_time":"2024-05-27T08:24:05.914281","exception":false,"start_time":"2024-05-27T08:24:05.8897","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.027032,"end_time":"2024-05-27T08:24:05.966477","exception":false,"start_time":"2024-05-27T08:24:05.939445","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if isTrain== True:\n    spec_xymasking = albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n                                              mask_x_length=cfg.size_x // 10, mask_y_length=cfg.n_mels // 10,\n                                              fill_value=0, mask_fill_value=0, p=1)\n\ndef spec_mixup(data, targets):\n    type = data.dtype\n\n    #只是改变顺序，不改变对应关系\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_targets = targets[indices]\n\n    data = np.array(data)\n    data_transposed = np.transpose(data, (2, 3, 1, 0))\n    data_transposed = spec_xymasking(image=data_transposed)[\"image\"]\n    data_transposed = np.transpose(data_transposed, (3, 2, 0, 1))  \n\n    #差异不为0的位置在掩码中为1，表示数据被改变；只混合被掩码覆盖的数据点\n    diff = data - data_transposed\n    mask = (diff != 0).astype(int)\n\n    shuffled_data_masked = (shuffled_data * mask)\n\n    new_data = torch.tensor(data_transposed, dtype=type) + torch.tensor(shuffled_data_masked, dtype=type)\n\n    lam = mask.sum() / len(data) / (cfg.n_mels*cfg.size_x)\n    new_targets = targets * (1-lam) + shuffled_targets *lam\n\n    return new_data, new_targets","metadata":{"papermill":{"duration":0.042092,"end_time":"2024-05-27T08:24:06.084224","exception":false,"start_time":"2024-05-27T08:24:06.042132","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:10.954012Z","iopub.execute_input":"2024-06-09T06:58:10.955175Z","iopub.status.idle":"2024-06-09T06:58:10.967059Z","shell.execute_reply.started":"2024-06-09T06:58:10.955066Z","shell.execute_reply":"2024-06-09T06:58:10.96588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">7 | Mel Spectrogram Generation </p>\n\n","metadata":{"papermill":{"duration":0.02796,"end_time":"2024-05-27T08:24:06.137985","exception":false,"start_time":"2024-05-27T08:24:06.110025","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#转换为Mel频谱表示\nspec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels,f_min=cfg.fmin,f_max=cfg.fmax,mel_scale='slaney',center=True, pad_mode='reflect'\n).to(device)\n#测试集\nvalid_spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.test_hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels,f_min=cfg.fmin,f_max=cfg.fmax,mel_scale='slaney',center=True, pad_mode='reflect'\n).to(device)\n#训练层\ntest_spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.test_hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels,f_min=cfg.fmin,f_max=cfg.fmax,mel_scale='slaney',center=True, pad_mode='reflect'\n).cpu()","metadata":{"papermill":{"duration":0.181583,"end_time":"2024-05-27T08:24:06.34538","exception":false,"start_time":"2024-05-27T08:24:06.163797","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:14.987688Z","iopub.execute_input":"2024-06-09T06:58:14.988151Z","iopub.status.idle":"2024-06-09T06:58:15.118213Z","shell.execute_reply.started":"2024-06-09T06:58:14.988117Z","shell.execute_reply":"2024-06-09T06:58:15.117197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">8 | Data Preparation Steps</p>\n\n\n \n","metadata":{"papermill":{"duration":0.024773,"end_time":"2024-05-27T08:24:06.395921","exception":false,"start_time":"2024-05-27T08:24:06.371148","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#处理标签、识别和删除重复的文件名\nsample_submission = pd.read_csv(cfg.dir+\"sample_submission.csv\")\nLABELS = list(sample_submission.set_index(\"row_id\").columns)\nLABELS[:5]\ntrain_csv = pd.read_csv(cfg.dir+\"train_metadata.csv\")\ntrain_csv['new_target'] = train_csv['primary_label'] + ' ' + train_csv['secondary_labels'].map(lambda x: ' '.join(ast.literal_eval(x)))\ntrain_csv['len_new_target'] =train_csv['new_target'].map(lambda x: len(x.split()))\ntrain_csv[\"len_new_target\"].value_counts().plot(kind=\"bar\", figsize=(4,2))\ntrain_csv[\"filename_tmp\"] = train_csv[\"filename\"].map(lambda x:x.split(\"/\")[1][:-4])\nduplicated_filenames = train_csv[\"filename_tmp\"].value_counts()[train_csv[\"filename_tmp\"].value_counts() > 1].index\ntrain_csv = train_csv[~train_csv[\"filename_tmp\"].isin(duplicated_filenames)]\ntrain_csv = train_csv.reset_index(drop=True)","metadata":{"papermill":{"duration":0.945215,"end_time":"2024-05-27T08:24:07.431523","exception":false,"start_time":"2024-05-27T08:24:06.486308","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:18.617571Z","iopub.execute_input":"2024-06-09T06:58:18.61871Z","iopub.status.idle":"2024-06-09T06:58:19.513717Z","shell.execute_reply.started":"2024-06-09T06:58:18.618672Z","shell.execute_reply":"2024-06-09T06:58:19.512526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\"> 9 | BirdCLEF Dataset Preparation </p>\n\n","metadata":{"papermill":{"duration":0.026002,"end_time":"2024-05-27T08:24:07.483224","exception":false,"start_time":"2024-05-27T08:24:07.457222","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BirdCLEF_Dataset(torch.utils.data.Dataset):\n    #augmentation 是否应用数据增强;是否真的有采用？\n    def __init__(self, df, augmentation=False, mode='train'):\n        if mode == 'train':\n            self.df = df.reset_index(drop=True)\n        elif mode == 'valid':\n            self.df = df.reset_index(drop=True)\n        else:\n            self.df = df\n        self.mode = mode\n        self.augmentation = augmentation\n    \n    def __len__(self):\n        return len(self.df)\n#规范化处理，数据在【0,1】之间\n    def normalize(self, x):\n        valid_values = x[x != float('-inf')]\n        mean_value = np.mean(valid_values)\n        x[x == float('-inf')] = mean_value\n        \n\n        x = x - x.min()\n        x = x / x.max()\n        return x\n#确保音频长度符合要求\n    def wave_tile_and_cutoff(self, data):\n      \n        drop_duration = cfg.sr*cfg.train_drop_duration\n        use_duration  = cfg.sr*cfg.train_duration\n        \n        if len(data[0]) > drop_duration: \n            data = data[:,drop_duration:]\n\n        if len(data[0]) < use_duration:\n            iter = 1 + (use_duration) // len(data[0])\n            data = np.tile(data, (1, iter))\n\n        data = data[:,:use_duration]\n        return data\n#避免过拟合\n    def label_smoothing(self, idx, target):\n    \n        secondary_target = target * cfg.secondary_label_value\n    \n        out_of_target_noise_intensity = cfg.smoothing_value/(len(LABELS)-1) \n        out_of_target_noise_array = torch.ones(target.shape) * out_of_target_noise_intensity\n        \n        secondary_target_with_noise = secondary_target + out_of_target_noise_array\n        secondary_target_with_noise = torch.clip(secondary_target_with_noise, min=0, max=cfg.secondary_label_value)\n    \n        primary_target = np.isin(LABELS, self.df.loc[idx, \"primary_label\"]).astype(int)\n        primary_target = torch.tensor(primary_target, dtype=torch.float32)\n\n        primary_and_secondary_target_with_noise = primary_target + secondary_target_with_noise\n        new_target = torch.clip(primary_and_secondary_target_with_noise, min=0, max=1)\n    \n        new_target = new_target - primary_target * cfg.smoothing_value\n    \n        return new_target\n\n    \n    def __getitem__(self, idx):\n#训练集\n        if self.mode == 'train':\n\n          \n            if cfg.useSecondary == True:\n                target = np.isin(LABELS, self.df.loc[idx, \"new_target\"].split()).astype(int)\n            else:\n                target = np.isin(LABELS, self.df.loc[idx, \"primary_label\"].split()).astype(int)\n            target = torch.tensor(target, dtype=torch.float32)\n          \n            target = self.label_smoothing(idx, target)\n            \n            fileID = self.df.loc[idx, 'fileID'] \n            \n            path = f\"{cfg.wave_path}{fileID}.npy\"\n            wave = np.load(path)\n            \n\n      \n            wave = self.wave_tile_and_cutoff(data=wave)\n\n            \n            input_duration = cfg.sr * cfg.slice_duration\n            \n            \n            if self.augmentation == True:\n               \n                if cfg.aug_wave_mixup > np.random.random():\n                    #train_duration -> slice_duration\n                    wave_reshape = wave.reshape(-1, input_duration)\n                    wave = mixup(data=wave_reshape, targets=target, alpha=cfg.alpha, mode=\"same_wave\")\n                    wave = wave[:1,:]\n                else:\n                    wave = wave[:, :input_duration]\n                \n     \n                wave = normal_augment(samples=wave, sample_rate=cfg.sr)\n\n    \n                wave = torch.tensor(wave).to(device)\n                mel_spec = spec_layer(wave)\n                mel_spec = np.array(mel_spec.cpu())\n\n                mel_spec = np.log(mel_spec)\n                for i in range(len(mel_spec)):\n                    mel_spec[i] = self.normalize(mel_spec[i])\n                mel_spec = torch.tensor(mel_spec)\n                mel_spec = mel_spec[:,:,:cfg.size_x]\n\n     \n                mel_spec = np.array(mel_spec.cpu())\n                mel_spec = np.transpose(mel_spec, (1, 2, 0))                \n                mel_spec = albumentations_augment(image=mel_spec)[\"image\"]\n                mel_spec = np.transpose(mel_spec, (2, 0, 1))\n\n\n                \n            else:\n                wave = wave[:, :input_duration]\n                \n                wave = torch.tensor(wave).to(device)\n                mel_spec = spec_layer(wave)\n                mel_spec = np.array(mel_spec.cpu())\n\n                mel_spec = np.log(mel_spec)\n\n                for i in range(len(mel_spec)):\n                    mel_spec[i] = self.normalize(mel_spec[i])\n                    \n\n                mel_spec = torch.tensor(mel_spec)\n                mel_spec = mel_spec[:,:,:cfg.size_x]\n\n            \n            mel_spec = torch.tensor(mel_spec)\n\n            \n            return mel_spec, target\n#验证集  用于评估模型的性能，不需要数据增强\n        elif self.mode == 'valid':\n            \n\n            if cfg.useSecondary == True:\n                target = np.isin(LABELS, self.df.loc[idx, \"new_target\"].split()).astype(int)\n            else:\n                target = np.isin(LABELS, self.df.loc[idx, \"primary_target\"].split()).astype(int)\n            target = torch.tensor(target, dtype=torch.float32)\n            \n            fileID = self.df.loc[idx, 'fileID'] \n            \n            path = f\"{cfg.wave_path}{fileID}.npy\"\n            wave = np.load(path)\n\n            wave = self.wave_tile_and_cutoff(data=wave)\n\n            input_duration = cfg.sr*cfg.test_duration\n            wave_reshape = wave.reshape(-1, input_duration)\n\n            wave_reshape = torch.tensor(wave_reshape).to(device)\n            mel_specs = valid_spec_layer(wave_reshape)\n            mel_specs = mel_specs.cpu().numpy()\n\n            mel_specs = np.log(mel_specs)\n            for i in range(len(mel_specs)):\n                mel_specs[i] = self.normalize(mel_specs[i])\n            mel_specs = torch.tensor(mel_specs)\n            \n            mel_specs = mel_specs[:,:,:cfg.size_x]\n\n            targets = torch.tile(target, dims=(mel_specs.shape[0],1))\n            return mel_specs, targets\n#测试集 使用未见过的数据测试模型的泛化能力\n        elif self.mode == 'test':\n\n            filepath = self.df[idx]\n            wave, _  = torchaudio.load(filepath)\n            wave = wave[:,:60*4*32000]\n\n            wave_reshaped = wave.reshape(-1, 1, cfg.test_duration*cfg.sr)\n            \n            mel_spec = test_spec_layer(wave_reshaped)\n            mel_spec = np.log(mel_spec)\n\n            mel_spec = np.array(mel_spec)\n            for i in range(len(mel_spec)):\n                mel_spec[i] = self.normalize(mel_spec[i])\n            mel_spec = torch.tensor(mel_spec)\n\n            mel_spec = mel_spec[:,:,:cfg.size_x]\n            return mel_spec\n#可以评估模型对未见数据的性能，尤其是在测试或验证阶段。\n        elif self.mode == 'clean':\n\n            filepath = self.df[idx]\n            wave, _  = torchaudio.load(filepath)\n\n            wave = wave[:, :6*cfg.test_duration*cfg.sr]\n\n            chunk_length = len(wave[0]) // (cfg.test_duration*cfg.sr)\n            \n            wave = wave[:,:chunk_length*cfg.test_duration*cfg.sr]\n\n            wave_reshaped = wave.reshape(-1, 1, cfg.test_duration*cfg.sr)\n            \n            mel_spec = test_spec_layer(wave_reshaped)\n            mel_spec = np.log(mel_spec)\n\n            mel_spec = np.array(mel_spec)\n            for i in range(len(mel_spec)):\n                mel_spec[i] = self.normalize(mel_spec[i])\n            mel_spec = torch.tensor(mel_spec)\n\n            return mel_spec, filepath","metadata":{"papermill":{"duration":0.078512,"end_time":"2024-05-27T08:24:07.588078","exception":false,"start_time":"2024-05-27T08:24:07.509566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:22.68003Z","iopub.execute_input":"2024-06-09T06:58:22.680454Z","iopub.status.idle":"2024-06-09T06:58:22.725718Z","shell.execute_reply.started":"2024-06-09T06:58:22.680417Z","shell.execute_reply":"2024-06-09T06:58:22.724262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isTrain:\n    print(\"train data\")\n    dataset = BirdCLEF_Dataset(df=train_csv, augmentation=True,  mode=\"train\")\n    data, target = dataset[270]\n    fig, ax = plt.subplots(figsize=(6,4))\n    plt.imshow(data[0], cmap=\"jet\", origin=\"lower\")\n    plt.show()\n    \n    print(\"validation data\")\n    dataset = BirdCLEF_Dataset(df=train_csv, augmentation=True,  mode=\"valid\")\n    data, target = dataset[270]\n    fig, axes = plt.subplots(figsize=(12,8), nrows=len(data), tight_layout=True)\n    for idx, ax in enumerate(axes.ravel()):\n        ax.imshow(data[idx], cmap=\"jet\", origin=\"lower\")","metadata":{"papermill":{"duration":0.040422,"end_time":"2024-05-27T08:24:07.705757","exception":false,"start_time":"2024-05-27T08:24:07.665335","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T07:01:25.445908Z","iopub.execute_input":"2024-06-09T07:01:25.447442Z","iopub.status.idle":"2024-06-09T07:01:25.461563Z","shell.execute_reply.started":"2024-06-09T07:01:25.44739Z","shell.execute_reply":"2024-06-09T07:01:25.460067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">10 | BirdModel : Flexible Pooling Architecture For Bird Sound Classification </p>\n\n\n\n","metadata":{"papermill":{"duration":0.025839,"end_time":"2024-05-27T08:24:07.757093","exception":false,"start_time":"2024-05-27T08:24:07.731254","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BirdModel(torch.nn.Module):\n    def __init__(self, model_name, pretrained, in_channels, num_classes, pool=\"default\"):\n        super().__init__()\n\n        self.pool = pool\n        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        #数值为均值以及标准差\n        if pool == \"default\":\n            self.backbone = timm.create_model(\n                model_name=model_name, pretrained=pretrained,\n                num_classes=0, in_chans=3)\n        #采用自定义的全局池化\n        else:\n            self.backbone = timm.create_model(\n                model_name=model_name, pretrained=pretrained,\n                num_classes=0, in_chans=3, global_pool=\"\")\n        #获取输出特征数量\n        in_features = self.backbone.num_features\n\n\n\n        self.max_pooling = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1),\n                                               torch.nn.Flatten(start_dim=1, end_dim=-1))\n        self.avg_pooling = torch.nn.Sequential(torch.nn.AdaptiveAvgPool2d(1),\n                                               torch.nn.Flatten(start_dim=1, end_dim=-1))\n        #批量归一层，线性层\n        self.both_pooling_neck = torch.nn.Sequential(torch.nn.BatchNorm1d(2*in_features),\n                                                     torch.nn.Linear(in_features=2*in_features, out_features=in_features))\n        \n        self.head = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(in_features),\n            torch.nn.Linear(in_features=in_features, out_features=256),\n            torch.nn.Hardswish(inplace=True),torch.nn.Dropout(0.1),\n            torch.nn.Linear(in_features=256, out_features=len(LABELS))  \n        )\n\n\n\n        self.active = torch.nn.Sigmoid()\n    def forward(self, x):\n        x = x.expand(-1, 3, -1, -1)\n        x = self.normalize(x)\n        x = self.backbone(x)\n\n        if self.pool == \"max\":\n            x = self.max_pooling(x)\n        elif self.pool == \"avg\":\n            x = self.avg_pooling(x)\n        elif self.pool == \"both\":\n            x_max = self.max_pooling(x)\n            x_avg = self.avg_pooling(x)\n            x = x_max + x_avg\n            # x = torch.cat([x_max, x_avg], dim=1)\n            # x = self.both_pooling_neck(x)\n         #池化后的输出模型传递到模型分类头部   \n        x = self.head(x)\n        # x = self.active(x)\n        return x","metadata":{"papermill":{"duration":0.048113,"end_time":"2024-05-27T08:24:07.883643","exception":false,"start_time":"2024-05-27T08:24:07.83553","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:50:58.768662Z","iopub.execute_input":"2024-06-07T14:50:58.769054Z","iopub.status.idle":"2024-06-07T14:50:58.781777Z","shell.execute_reply.started":"2024-06-07T14:50:58.769022Z","shell.execute_reply":"2024-06-07T14:50:58.780506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">11 | Stratified k-Fold Cross-Validation and Random Seed Setting 🐦</p>\n\n\n1. **Stratified K-Fold Cross-Validation**:\n   - Stratified K-Fold cross-validation is a technique used to evaluate the performance of a machine learning model. It ensures that each fold of the dataset has approximately the same proportion of samples from each class, which is particularly useful for imbalanced datasets.\n   - `StratifiedKFold` is a class from the scikit-learn library that splits a dataset into K folds while preserving the percentage of samples for each class.\n   - In the `for` loop:\n       - `skf.split(train_csv, train_csv['primary_label'])` splits the dataset (`train_csv`) into train and validation sets for each fold, ensuring that each fold maintains the same distribution of classes as the original dataset.\n       - `train_index` and `valid_index` contain the indices of samples for the training and validation sets for the current fold.\n       - `enumerate(skf.split(...))` iterates over each fold, providing the fold index (`fold`) and the corresponding train/validation indices.\n       - `train_csv.loc[valid_index, 'fold'] = int(fold)` assigns the fold index to the validation samples in the `fold` column of the DataFrame `train_csv`, indicating which fold each sample belongs to.\n\n2. **Random Seed Setting**:\n   - Setting random seeds ensures reproducibility of results in machine learning experiments. It initializes the random number generators with a fixed seed, so the same sequence of random numbers is generated every time the code is run.\n   - `set_random_seed` is a function defined to set the random seed across different random number generators used in the experiment.\n   - Inside the function:\n       - `random.seed(seed)`, `np.random.seed(seed)`, and `os.environ[\"PYTHONHASHSEED\"] = str(seed)` set the random seed for the Python built-in random number generator, NumPy, and hash randomization, respectively.\n       - `torch.manual_seed(seed)` sets the random seed for the PyTorch library for CPU operations.\n       - `torch.cuda.manual_seed(seed)` sets the random seed for GPU operations in PyTorch.\n       - `torch.backends.cudnn.deterministic = deterministic` ensures deterministic behavior of CuDNN (CUDA Deep Neural Network library) for GPU operations in PyTorch, which can affect the performance but ensures reproducibility.\n\n","metadata":{"papermill":{"duration":0.025698,"end_time":"2024-05-27T08:24:07.936261","exception":false,"start_time":"2024-05-27T08:24:07.910563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#分层抽样的K折交叉验证，获取行索引\nskf = StratifiedKFold(n_splits=cfg.nfolds, shuffle=True, random_state=cfg.seed)\nfor fold, (train_index, valid_index) in enumerate(skf.split(train_csv, train_csv['primary_label'])):\n    train_csv.loc[valid_index, 'fold'] = int(fold)\n    \n#分组统计 以及评估分层抽样 K 折交叉验证是否成功地保持了每个折叠中类别分布的一致性。\nif isTrain:\n    train_csv.groupby(\"fold\", as_index=False)[\"primary_label\"].value_counts()   \n    \n    \ndef set_random_seed(seed: int = 42, deterministic: bool = False):\n    \"\"\"Set seeds\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = deterministic  # type: ignore    ","metadata":{"papermill":{"duration":0.082794,"end_time":"2024-05-27T08:24:08.04628","exception":false,"start_time":"2024-05-27T08:24:07.963486","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:51:04.538613Z","iopub.execute_input":"2024-06-07T14:51:04.539019Z","iopub.status.idle":"2024-06-07T14:51:04.576722Z","shell.execute_reply.started":"2024-06-07T14:51:04.538989Z","shell.execute_reply":"2024-06-07T14:51:04.575372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\"> 12 | BCEFocalLoss: Binary Cross-Entropy Focal Loss 🐦</p>\n\n\n1. **BCEFocalLoss Class**:\n    - This class defines a custom loss function called `BCEFocalLoss` for binary classification tasks.\n    - It inherits from `nn.Module`, indicating that it's a PyTorch module.\n\n2. **Initialization**:\n    - The `__init__` method initializes the loss function with two parameters: `alpha` and `gamma`.\n    - `alpha` (default value: 0.25) controls the balance between positive and negative class samples in the loss calculation.\n    - `gamma` (default value: 2.0) controls the degree of focus on hard-to-classify examples.\n\n3. **Forward Method**:\n    - The `forward` method computes the loss given model predictions (`preds`) and ground truth labels (`targets`).\n    - It first calculates the binary cross-entropy (BCE) loss using `nn.BCEWithLogitsLoss` with the option `reduction='none'` to compute the loss per sample without averaging.\n    - `probas = torch.sigmoid(preds)` computes the sigmoid activation of the model predictions to obtain probabilities.\n\n4. **Focal Loss Components**:\n    - Focal loss introduces two additional components: focal term (`tmp`) and smooth term (`smp`).\n    - `tmp` calculates the focal loss for positive class samples, where the focus is increased for misclassified samples (`(1. - probas)**self.gamma` increases the loss for hard-to-classify examples).\n    - `smp` calculates the focal loss for negative class samples, focusing on correctly classified samples (`probas**self.gamma` increases the loss for hard-to-classify examples).\n    - Both `tmp` and `smp` are multiplied by the BCE loss to incorporate the original loss calculation.\n\n5. **Final Loss Calculation**:\n    - The final loss is calculated as the sum of `tmp` and `smp`, followed by taking the mean over all samples.\n    - This mean loss value is returned as the output of the `forward` method.\n\n","metadata":{"papermill":{"duration":0.025938,"end_time":"2024-05-27T08:24:08.098639","exception":false,"start_time":"2024-05-27T08:24:08.072701","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BCEFocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, preds, targets):\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n        probas = torch.sigmoid(preds)\n\n        \n\n        tmp = targets * self.alpha * (1. - probas)**self.gamma * bce_loss\n        smp = (1. - targets) * probas**self.gamma * bce_loss\n        \n        loss = tmp + smp\n        loss = loss.mean()\n        return loss","metadata":{"papermill":{"duration":0.039605,"end_time":"2024-05-27T08:24:08.164291","exception":false,"start_time":"2024-05-27T08:24:08.124686","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:51:09.748386Z","iopub.execute_input":"2024-06-07T14:51:09.748814Z","iopub.status.idle":"2024-06-07T14:51:09.757526Z","shell.execute_reply.started":"2024-06-07T14:51:09.748782Z","shell.execute_reply":"2024-06-07T14:51:09.755505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">13 | Initialization Function For Training </p>\n\n1. **Model Initialization**:\n   - The function initializes the neural network model using the `BirdModel` class, which is customized for bird sound classification.\n   - It sets parameters such as the model architecture (`model_name`), whether to use pre-trained weights (`pretrained`), number of input channels (`in_channels`), number of output classes (`num_classes`), and pooling type (`pool`).\n\n2. **Optimizer Selection**:\n   - Depending on the configuration (`cfg.optimizer`), the function selects the optimizer for training.\n   - If `cfg.optimizer` is set to `'adan'`, it uses the custom optimizer `Adan` with specific parameters like learning rate (`lr`), betas, and weight decay.\n   - Otherwise, it uses the standard AdamW optimizer from PyTorch with parameters such as learning rate (`lr`) and weight decay.\n\n3. **Learning Rate Scheduler**:\n   - The function initializes a learning rate scheduler using `torch.optim.lr_scheduler.OneCycleLR`.\n   - This scheduler adjusts the learning rate during training, starting from an initial value (`cfg.lr`), and following a one-cycle policy with specified parameters such as the maximum number of epochs (`cfg.max_epoch`), percentage of epochs to increase/decrease learning rate (`pct_start`), and step size (`steps_per_epoch`).\n\n4. **Gradient Scaler (Automatic Mixed Precision)**:\n   - Automatic Mixed Precision (AMP) is a technique that combines single and half-precision floating-point arithmetic to speed up training while maintaining numerical stability.\n   - The function initializes a gradient scaler using `amp.GradScaler` with the option to enable or disable AMP based on the configuration (`cfg.enable_amp`).\n\n5. **Loss Function Initialization**:\n   - Depending on the loss type specified in the configuration (`cfg.loss_type`), the function initializes the loss function.\n   - If `cfg.loss_type` is set to `\"BCEWithLogitsLoss\"`, it uses the binary cross-entropy loss with logits (`torch.nn.BCEWithLogitsLoss`).\n   - If `cfg.loss_type` is set to `\"BCEFocalLoss\"`, it uses the custom focal loss function `BCEFocalLoss` with a specified `alpha` value.\n\n6. **Returning Initialized Components**:\n   - The function returns the initialized model, optimizer, scheduler, scaler, and loss function, all moved to the appropriate device (`device`), typically GPU.\n\n","metadata":{"papermill":{"duration":0.025553,"end_time":"2024-05-27T08:24:08.215738","exception":false,"start_time":"2024-05-27T08:24:08.190185","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def initialization():\n    model = BirdModel(model_name=cfg.model_name, pretrained=True, in_channels=3, num_classes=len(LABELS), pool=cfg.pool_type)\n    \n    if cfg.optimizer=='adan':\n        optimizer = Adan(model.parameters(), lr=cfg.lr, betas=(0.02, 0.08, 0.01), weight_decay=cfg.weight_decay)\n    else:\n        optimizer = torch.optim.AdamW(params=model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer, epochs=cfg.max_epoch,\n        pct_start=0.0, steps_per_epoch=len(train_dataloader),\n        max_lr=cfg.lr, div_factor=25, final_div_factor=4.0e-01\n    )\n    \n    scaler = amp.GradScaler(enabled=cfg.enable_amp)\n    if cfg.loss_type == \"BCEWithLogitsLoss\":\n        loss_func = torch.nn.CrossEntropyLoss()\n    elif cfg.loss_type == \"BCEFocalLoss\":\n        loss_func = BCEFocalLoss(alpha=1)\n    \n    \n\n\n    return model.to(device), optimizer, scheduler, scaler, loss_func.to(device)","metadata":{"papermill":{"duration":0.041677,"end_time":"2024-05-27T08:24:08.283638","exception":false,"start_time":"2024-05-27T08:24:08.241961","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:51:14.877655Z","iopub.execute_input":"2024-06-07T14:51:14.878075Z","iopub.status.idle":"2024-06-07T14:51:14.887035Z","shell.execute_reply.started":"2024-06-07T14:51:14.878041Z","shell.execute_reply":"2024-06-07T14:51:14.885739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">14 | Training And Evaluation Functions 🐦</p>\n\n1. **`train_one_loop` Function**:\n   - This function performs one epoch of training.\n   - It iterates through the training data (`dataloader`) and updates the model parameters based on the calculated loss.\n   - Within each iteration:\n     - The data and labels are moved to the appropriate device (`device`).\n     - The gradients are zeroed using `optimizer.zero_grad()` to clear the previous gradients.\n     - Inside the training loop, gradient scaling is applied using AMP (Automatic Mixed Precision) to improve numerical stability and speed up training.\n     - The loss is computed using the specified loss function (`loss_fn`) and backpropagated through the network.\n     - The optimizer's learning rate is adjusted using the scheduler (`scheduler.step()`).\n     - The loss value is accumulated for monitoring training progress.\n   - After processing all batches, the average training loss is calculated and logged (if using Weights & Biases for logging).\n\n2. **`mixup_one_loop` Function**:\n   - This function performs one epoch of training with mixup augmentation.\n   - Mixup is a data augmentation technique that blends pairs of examples and their corresponding labels.\n   - It follows a similar structure to `train_one_loop`, but before feeding the data to the model, it applies mixup augmentation based on a probability threshold (`cfg.aug_spec_mixup_prob`).\n   - Mixup can be applied either on different waveforms (`\"other_wave\"`) or on spectrograms (`\"spec_mixup\"`).\n   - The rest of the process, including loss computation and optimization, remains the same.\n\n3. **`evaluate_validation` Function**:\n   - This function evaluates the model on the validation dataset (`dataloader`) after each epoch of training.\n   - It calculates validation loss and various evaluation metrics such as AUC (Area Under the ROC Curve), F1-score, precision, and more.\n   - Inside the evaluation loop:\n     - The model makes predictions on the validation data.\n     - Predictions are compared with the ground truth labels to compute the evaluation metrics.\n     - The validation loss is computed using the specified loss function.\n   - The function returns the validation loss and evaluation metrics, which can be used for monitoring the model's performance during training.\n\nThese functions collectively handle the training and evaluation process of the bird sound classification model, including data processing, model training, and performance evaluation. Additionally, they provide flexibility in choosing different training strategies such as mixup augmentation and support for monitoring training progress using Weights & Biases.","metadata":{"papermill":{"duration":0.026164,"end_time":"2024-05-27T08:24:08.335485","exception":false,"start_time":"2024-05-27T08:24:08.309321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_one_loop(model, optimizer, scaler, scheduler, dataloader, loss_fn):\n    trainloss = 0; model.train()\n\n    count = 0\n    for idx, (data, label) in enumerate(tqdm(dataloader,leave=False ,desc=\"[train]\")):\n        # label = label.reshape(-1, len(LABELS))\n        \n        data, label = data.to(device), label.to(device)\n        \n        optimizer.zero_grad()\n        with amp.autocast(cfg.enable_amp, dtype=torch.bfloat16):\n        # with amp.autocast(cfg.enable_amp):\n            pred = model.forward(data)\n            loss = loss_fn(pred, label)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n        \n        trainloss += loss.item()\n        # print(idx, loss.item())\n        # if cfg.wandb == True:\n        #     wandb.log({f\"train_loss\": loss.item(), f\"lr\":scheduler.get_lr()[0]})\n        del data, label, loss\n        count += 1\n        # if count == 300:\n        # break\n    trainloss /= len(dataloader)\n    if cfg.wandb == True:\n        wandb.log({f\"train_loss\": trainloss, f\"lr\":scheduler.get_lr()[0]})\n    return model, optimizer, scaler, scheduler, trainloss\n\n\ndef mixup_one_loop(model, optimizer, scaler, scheduler, dataloader, loss_fn):\n    trainloss = 0; model.train()\n\n    count = 0\n    for idx, (data, label) in enumerate(tqdm(dataloader,leave=False ,desc=\"[train]\")):\n        if np.random.random()>cfg.aug_spec_mixup_prob:\n            data, label = mixup(data=data, targets=label, alpha=cfg.alpha, mode=\"other_wave\")\n        else:\n            data, label = spec_mixup(data=data, targets=label)\n        data, label = data.to(device), label.to(device)\n        \n        optimizer.zero_grad()\n        with amp.autocast(cfg.enable_amp, dtype=torch.bfloat16):\n        # with amp.autocast(cfg.enable_amp):\n            pred = model.forward(data)\n            loss = loss_fn(pred, label)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n        \n        trainloss += loss.item()\n        # print(idx, loss.item())\n        # if cfg.wandb == True:\n        #     wandb.log({f\"lr\":scheduler.get_lr()[0]})\n        del data, label, loss\n        count += 1\n        # if count == 300:\n        # break\n    trainloss /= len(dataloader)\n    if cfg.wandb == True:\n        wandb.log({f\"train_loss\": trainloss, f\"lr\":scheduler.get_lr()[0]})\n    return model, optimizer, scaler, scheduler, trainloss\n\nfrom sklearn.metrics import f1_score\ndef evaluate_validation(model, dataloader, loss_fn):\n    validloss=0\n    model.eval()\n\n    preds, trues, targets = [], [], []\n    \n    for idx, (data, label) in enumerate(tqdm(dataloader,leave=False ,desc=\"[valid]\")):\n        # label = label.reshape(-1, len(LABELS))\n\n        d = data[0].unsqueeze(1)\n        label = label[0]\n        \n        d = d.to(device)\n        # with amp.autocast(cfg.enable_amp):\n        pred = model.forward(d)\n\n        preds.extend(pred.detach().cpu())\n        trues.extend(label)\n        targets.extend(label.argmax(axis=1))\n        \n    #======================== metrics ========================#\n    # y_preds = torch.stack(preds)\n    t = torch.stack(preds)\n    t = torch.sigmoid(t)\n    targets = torch.tensor(targets)\n    y_trues = torch.stack(trues)\n\n\n    validloss = loss_fn(torch.stack(preds), torch.stack(trues))\n    #     # print(idx, loss)\n    #     # wandb.log({\"valid_loss\": loss})\n\n    # validloss /= len(dataloader)\n    \n\n\n# 假设 t 是一个 PyTorch 张量，targets 是标签的列表\n# 将 targets 转换为 PyTorch 张量\n\n    targets_tensor = torch.tensor(targets)\n\n    def calculate_f1_at_threshold(y_true, predictions, threshold, average=\"micro\"):\n    # 应用阈值并计算F1分数\n        binary_predictions = (predictions > threshold).int()\n        return f1_score(y_true, binary_predictions.numpy(), average=average)\n\n# 计算不同阈值下的F1分数\n    f1_scores = {\n        \"F1_03\": calculate_f1_at_threshold(targets_tensor, t, 0.3),\n        \"F1_05\": calculate_f1_at_threshold(targets_tensor, t, 0.5)\n    }\n\n    # 计算AUC和精确度\n    auc = multiclass_auroc(t, targets_tensor, len(LABELS), \"macro\")\n    prec = multiclass_precision(t, targets_tensor, len(LABELS), \"macro\")\n\n     # 计算微观和宏观平均的F1分数\n    f1 = multiclass_f1_score(t, targets_tensor, len(LABELS), \"micro\")\n    f1_macro = multiclass_f1_score(t, targets_tensor, len(LABELS), \"macro\")\n\n# 打印结果\n    print(f\"AUC (Macro): {auc}\")\n    print(f\"Precision (Macro): {prec}\")\n    print(f\"F1 Score (Micro): {f1}\")\n    print(f\"F1 Score (Macro): {f1_macro}\")\n    for key, value in f1_scores.items():\n        print(f\"{key}: {value}\")\n\n   \n    if cfg.wandb == True:\n        wandb.log({f\"valid_loss\": validloss,\n                   f\"AUC\":auc,\n                   # \"auc_micro\":auc_micro,\n                   \"precision\":prec, \n                   # \"recall\":rec, \n                   # \"accuracy\":acc,\n                   f\"F1\":f1,\n                   \"F1_macro\":f1_macro,\n                   f\"F1 30%\":f1_03,\n                   f\"F1 50%\":f1_05})\n    return validloss, auc, f1, f1_03, f1_05, sk_f1_30, sk_f1_50","metadata":{"papermill":{"duration":0.063951,"end_time":"2024-05-27T08:24:08.425685","exception":false,"start_time":"2024-05-27T08:24:08.361734","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T15:48:27.859167Z","iopub.execute_input":"2024-06-07T15:48:27.859602Z","iopub.status.idle":"2024-06-07T15:48:27.885546Z","shell.execute_reply.started":"2024-06-07T15:48:27.859568Z","shell.execute_reply":"2024-06-07T15:48:27.884129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isTrain == True:\n    tmp_params = dict(vars(config))\n    del tmp_params['__module__'],tmp_params['__dict__'],tmp_params['__weakref__'],tmp_params['__doc__']\n\ndef get_oversampled_df(df):\n    \n    new_df = [df]\n\n    low_sample_birds = df[\"primary_label\"].value_counts()[df[\"primary_label\"].value_counts() < cfg.oversample_threthold].index\n    for bird in low_sample_birds:\n        tmp = df[df[\"primary_label\"] == bird]\n        data_num = len(tmp)\n    \n        tiles = 1 + cfg.oversample_threthold // data_num\n    \n        tile_df = []\n        for i in range(tiles):\n            tile_df.append(tmp)\n    \n        tiled_df = pd.concat(tile_df)\n        piece = tiled_df[data_num:cfg.oversample_threthold]\n        new_df.append(piece)\n    \n    return pd.concat(new_df)","metadata":{"papermill":{"duration":0.042146,"end_time":"2024-05-27T08:24:08.546191","exception":false,"start_time":"2024-05-27T08:24:08.504045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T15:48:35.763836Z","iopub.execute_input":"2024-06-07T15:48:35.764806Z","iopub.status.idle":"2024-06-07T15:48:35.772703Z","shell.execute_reply.started":"2024-06-07T15:48:35.76477Z","shell.execute_reply":"2024-06-07T15:48:35.77149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isTrain == True:\n    set_random_seed(seed=42)\n    \n    \n    if cfg.wandb == True:\n        wandb.init(project='BirdCLEF_cv_ver2', name=f\"{name}\",\n                   config=tmp_params)\n        \n    # for fold in range(cfg.nfolds):\n    for fold in cfg.inference_folds:\n        train_ = train_csv.loc[train_csv[\"fold\"]!=fold]\n\n        if cfg.oversample == True:\n            train = get_oversampled_df(df=train_)\n        else:\n            train = train_\n        \n        augme_dataset = BirdCLEF_Dataset(df=train, augmentation=True, mode='train')\n        augme_dataloader = torch.utils.data.DataLoader(dataset=augme_dataset, batch_size=cfg.train_batchsize, shuffle=True)\n\n        train_dataset = BirdCLEF_Dataset(df=train, augmentation=False, mode='train')\n        train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=cfg.train_batchsize, shuffle=True)\n        \n        valid = train_csv.loc[train_csv[\"fold\"]==fold]\n        valid_dataset = BirdCLEF_Dataset(df=valid, augmentation=False, mode='valid')\n        valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=cfg.valid_batchsize, shuffle=False)\n    \n        model, optimizer, scheduler, scaler, loss_func =  initialization()\n    \n    \n        best_f1 = 0\n        best_auc = 0\n        best_loss = 1.00000\n        for e in range(cfg.max_epoch):\n            start_time = time.time()\n            if e < cfg.aug_epoch:\n                if cfg.aug_spec_mixup > np.random.random():\n                    model, optimizer, scaler, shcheduler, train_loss = mixup_one_loop(model=model,optimizer=optimizer,scaler=scaler, \n                                                                                          scheduler=scheduler,dataloader=augme_dataloader, loss_fn=loss_func)\n                else:\n                    model, optimizer, scaler, shcheduler, train_loss = train_one_loop(model=model,optimizer=optimizer,scaler=scaler, \n                                                                                          scheduler=scheduler,dataloader=augme_dataloader, loss_fn=loss_func)\n\n            else:\n                model, optimizer, scaler, shcheduler, train_loss = train_one_loop(model=model,optimizer=optimizer,scaler=scaler, \n                                                                                          scheduler=scheduler,dataloader=train_dataloader, loss_fn=loss_func)\n            \n            valid_loss, auc, f1, f1_03, f1_05, sk_f1_30, sk_f1_50 = evaluate_validation(model=model, dataloader=valid_dataloader, loss_fn=loss_func)\n            # print(f\"epoch {e} , train_loss is {train_loss}, valid_loss is {valid_loss}\")\n            \n            if best_loss > valid_loss:\n                end_time = time.time()\n                print(f\"[epoch {str(e).zfill(2)}] AUC{auc: .4f}, F1{f1: .4f}, F1_03{f1_03: .4f}, F1_05{f1_05: .4f}\")\n                print(f\"[epoch {str(e).zfill(2)}] SKF1_03{sk_f1_30: .4f}, SKF1_05{sk_f1_50: .4f}\")\n                print(f\"[epoch {str(e).zfill(2)}] valid_loss {valid_loss: .6f}\")\n                print(f\"[epoch {str(e).zfill(2)}] update loss {best_loss: .6f} --> {valid_loss: .6f} {(end_time - start_time): .1f}[s]\")\n                print(f\"[epoch {str(e).zfill(2)}] update auc score {best_auc: .6f} --> {auc: .6f} {(end_time - start_time): .1f}[s]\")\n                model_name = f'{name}/checkpoint/fold_{fold}_snapshot_epoch_{str(e).zfill(2)}.pth'\n                best_model = model\n                best_loss = valid_loss\n                best_auc = auc\n                best_f1 = f1\n            else:\n                end_time = time.time()\n                print(f\"[epoch {str(e).zfill(2)}] NOT update loss {best_loss: .6f} <-- {valid_loss: .6f} {(end_time - start_time): .1f}[s]\")\n                print(f\"[epoch {str(e).zfill(2)}] NOT update score {best_auc: .6f} <-- {auc: .6f} {(end_time - start_time): .1f}[s]\")\n\n        if cfg.wandb == True:\n            wandb.log({f\"best_loss\": best_loss,\n                       f\"best_f1\": best_f1,\n                       f\"best_auc\":best_auc})\n\n        torch.save(best_model.state_dict(), model_name)\n        \n        del model, best_model\n        gc.collect()\n        torch.cuda.empty_cache()\n        print(\"--\")\n","metadata":{"papermill":{"duration":0.05756,"end_time":"2024-05-27T08:24:08.683435","exception":false,"start_time":"2024-05-27T08:24:08.625875","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T15:48:40.873828Z","iopub.execute_input":"2024-06-07T15:48:40.874209Z","iopub.status.idle":"2024-06-07T15:48:40.893806Z","shell.execute_reply.started":"2024-06-07T15:48:40.874179Z","shell.execute_reply":"2024-06-07T15:48:40.892257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">15 | Model Loading For Inference 🐦</p>\n\n1. **Initializing Dictionaries:**\n   - Two dictionaries, `models` and `models_names`, are initialized to store loaded models and their corresponding names, respectively.\n\n2. **Iterating Over Folds:**\n   - The code iterates over each fold for which inference is required (`for fold in cfg.inference_folds:`).\n\n3. **Loading Trained Model:**\n   - The path to the best-performing model checkpoint for the current fold is obtained using `glob.glob`.\n   - The `BirdModel` class is instantiated to create a new model instance with the same architecture as the trained model.\n   - The model's state dictionary is loaded from the saved checkpoint file using `torch.load`.\n   - The loaded model is set to evaluation mode using `model.eval()`.\n\n4. **Storing Loaded Models and Names:**\n   - The loaded model is stored in the `models` dictionary with the fold index as the key.\n   - The name of the ONNX file for the model is generated from the checkpoint file path and stored in the `models_names` dictionary.\n\n5. **Printing Model Path and ONNX Name:**\n   - The path of the loaded model checkpoint file and the corresponding ONNX file name are printed for verification.\n\n","metadata":{"papermill":{"duration":0.025863,"end_time":"2024-05-27T08:24:08.735311","exception":false,"start_time":"2024-05-27T08:24:08.709448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"models = dict()\nmodels_names = dict()\n# for fold in range(cfg.nfolds):\nfor fold in cfg.inference_folds:\n    bestmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.pth\"))[-1]\n\n    print(bestmodel_path)\n    model = BirdModel(model_name=cfg.model_name, pretrained=False, in_channels=1, num_classes=len(LABELS))\n    model.load_state_dict(torch.load(bestmodel_path, map_location=torch.device('cpu')))\n    model = model.eval()\n    models[fold] = model\n\n    models_names[fold] = bestmodel_path.split(\".\")[0]+\".onnx\"\n    print(models_names[fold])","metadata":{"papermill":{"duration":0.614286,"end_time":"2024-05-27T08:24:09.375315","exception":false,"start_time":"2024-05-27T08:24:08.761029","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:00.441884Z","iopub.execute_input":"2024-06-06T03:04:00.442252Z","iopub.status.idle":"2024-06-06T03:04:00.739291Z","shell.execute_reply.started":"2024-06-06T03:04:00.442224Z","shell.execute_reply":"2024-06-06T03:04:00.737987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_audio_dir = f\"{cfg.dir}test_soundscapes/\"\nfile_list = glob.glob(test_audio_dir+\"*.ogg\")\nfile_list = sorted(file_list)\n\n\ntest_dataset = BirdCLEF_Dataset(df=file_list, mode=\"test\")\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                              batch_size=1, \n                                              shuffle=False)\n\ninput_tensor = torch.randn((48, 1, cfg.n_mels, cfg.size_x+1))  # input shape\noutput_names=['output']\ninput_names=[\"x\"]\n\n\n# models_names = []\nmodels_names = dict()\n# for fold in range(cfg.nfolds):\nfor fold in cfg.inference_folds:\n    onnxmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.onnx\"))[-1]\n\n    print(onnxmodel_path)\n\n    models_names[fold] = onnxmodel_path\n    \n    \nonnx_sessions = dict()\n# for fold in range(cfg.nfolds):\nfor fold in cfg.inference_folds:\n\n    onnx_model = onnx.load(models_names[fold])\n    onnx_model_graph = onnx_model.graph\n    onnx_session = ort.InferenceSession(onnx_model.SerializeToString())\n\n    onnx_sessions[fold] = onnx_session    ","metadata":{"papermill":{"duration":0.449231,"end_time":"2024-05-27T08:24:09.902461","exception":false,"start_time":"2024-05-27T08:24:09.45323","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:00.743192Z","iopub.execute_input":"2024-06-06T03:04:00.744411Z","iopub.status.idle":"2024-06-06T03:04:01.037925Z","shell.execute_reply.started":"2024-06-06T03:04:00.744364Z","shell.execute_reply":"2024-06-06T03:04:01.036509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\npredictions = []\nfor data in tqdm(test_dataloader):\n    \n    preds = []\n    \n#     for fold, session in enumerate(onnx_sessions):\n    for fold in cfg.inference_folds:\n        session = onnx_sessions[fold]\n        pred = session.run(output_names, {input_names[0]: data[0].numpy()})[0]\n        \n        pred = torch.sigmoid(torch.tensor(pred))\n        preds.append(pred)\n    preds_per_batch = torch.stack(preds, axis=0).mean(axis=0)\n    \n    predictions.extend(preds_per_batch)\n    \nif len(predictions)>0:\n    predictions = torch.stack(predictions)\nelse:\n    predictions = predictions\nend_time = time.time()\nuse_time = end_time - start_time","metadata":{"papermill":{"duration":0.069935,"end_time":"2024-05-27T08:24:10.05298","exception":false,"start_time":"2024-05-27T08:24:09.983045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:01.04206Z","iopub.execute_input":"2024-06-06T03:04:01.042495Z","iopub.status.idle":"2024-06-06T03:04:01.076097Z","shell.execute_reply.started":"2024-06-06T03:04:01.042464Z","shell.execute_reply":"2024-06-06T03:04:01.074716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">16 | Final Submission 📝</p>\n\n\n","metadata":{"papermill":{"duration":0.025943,"end_time":"2024-05-27T08:24:10.105111","exception":false,"start_time":"2024-05-27T08:24:10.079168","status":"completed"},"tags":[]}},{"cell_type":"code","source":"bird_cols = sample_submission.columns[1:]\ndf = pd.DataFrame(columns=['row_id']+list(bird_cols))\n\n\nrow_list = []\nfor file in file_list:\n    dataname = file.split(\"/\")[-1][:-4]\n    for i in range(int(4*60/5)):\n        row = f\"{dataname}_{(i+1)*5}\"\n        row_list.append(row)\n        \n        \n        \ndf['row_id'] = row_list        \n\nif len(predictions) < 1:\n    pass\nelse:\n    df[bird_cols] = predictions\n    \n    \ndf.to_csv(\"submission1.csv\", index=False)     ","metadata":{"papermill":{"duration":0.055183,"end_time":"2024-05-27T08:24:10.186739","exception":false,"start_time":"2024-05-27T08:24:10.131556","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:01.078034Z","iopub.execute_input":"2024-06-06T03:04:01.078592Z","iopub.status.idle":"2024-06-06T03:04:01.10317Z","shell.execute_reply.started":"2024-06-06T03:04:01.078554Z","shell.execute_reply":"2024-06-06T03:04:01.101673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:01.105134Z","iopub.execute_input":"2024-06-06T03:04:01.105549Z","iopub.status.idle":"2024-06-06T03:04:01.135698Z","shell.execute_reply.started":"2024-06-06T03:04:01.105517Z","shell.execute_reply":"2024-06-06T03:04:01.133995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## another","metadata":{}},{"cell_type":"code","source":"import sys, os\nsys.path.append('/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle')\n!pip install -q /kaggle/input/tensorflow-extra-lib-ds/tensorflow_extra-1.0.2-py3-none-any.whl --no-deps","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:01.137495Z","iopub.execute_input":"2024-06-06T03:04:01.138048Z","iopub.status.idle":"2024-06-06T03:04:23.851124Z","shell.execute_reply.started":"2024-06-06T03:04:01.138Z","shell.execute_reply":"2024-06-06T03:04:23.849563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.get_logger().setLevel('ERROR')\ntf.autograph.set_verbosity(0)\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nfrom glob import glob\nfrom tqdm import tqdm\ntqdm.pandas()\nimport gc\nimport librosa\nimport sklearn\nimport time\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport librosa.display as lid\nimport IPython.display as ipd\n\nimport tensorflow as tf\ntf.config.optimizer.set_jit(True) # enable xla for speed up\nimport tensorflow_io as tfio\nimport tensorflow.keras.backend as K\n\nimport efficientnet.tfkeras as efn\nimport tensorflow_extra as tfe","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.853579Z","iopub.execute_input":"2024-06-06T03:04:23.854124Z","iopub.status.idle":"2024-06-06T03:04:23.874036Z","shell.execute_reply.started":"2024-06-06T03:04:23.854074Z","shell.execute_reply":"2024-06-06T03:04:23.872447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    debug = False\n    verbose = 0\n    \n    device = 'CPU'\n    seed = 42\n    \n    # Input image size and batch size\n    img_size = [128, 384]\n    batch_size = 16\n    infer_bs = 2\n    tta = 1\n    drop_remainder = True\n    \n    # STFT parameters\n    duration = 5 # duration for test\n    train_duration = 10\n    sample_rate = 32000\n    downsample = 1\n    audio_len = duration*sample_rate\n    nfft = 2028\n    window = 2048\n    hop_length = train_duration*32000 // (img_size[1] - 1)\n    fmin = 20\n    fmax = 16000\n    normalize = True\n\n    # Data Preprocessing Settings\n    class_names = sorted(os.listdir('/kaggle/input/birdclef-2024/train_audio/'))\n    num_classes = len(class_names)\n    class_labels = list(range(num_classes))\n    label2name = dict(zip(class_labels, class_names))\n    name2label = {v:k for k,v in label2name.items()}\n    \n    target_col = ['target']\n    tab_cols = ['filename','common_name','rate']","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.876045Z","iopub.execute_input":"2024-06-06T03:04:23.876597Z","iopub.status.idle":"2024-06-06T03:04:23.895227Z","shell.execute_reply.started":"2024-06-06T03:04:23.876555Z","shell.execute_reply":"2024-06-06T03:04:23.89366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.896759Z","iopub.execute_input":"2024-06-06T03:04:23.897532Z","iopub.status.idle":"2024-06-06T03:04:23.971541Z","shell.execute_reply.started":"2024-06-06T03:04:23.897492Z","shell.execute_reply":"2024-06-06T03:04:23.968281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_device():\n    \"Detect and intializes GPU/TPU automatically\"\n    # Check TPU category\n    tpu = 'local' if CFG.device=='TPU-VM' else None\n    try:\n        # Connect to TPU\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=tpu) \n        # Set TPU strategy\n        strategy = tf.distribute.TPUStrategy(tpu)\n        print(f'> Running on {CFG.device} ', tpu.master(), end=' | ')\n        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n        device=CFG.device\n    except:\n        # If TPU is not available, detect GPUs\n        gpus = tf.config.list_logical_devices('GPU')\n        ngpu = len(gpus)\n         # Check number of GPUs\n        if ngpu:\n            # Set GPU strategy\n            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n            # Print GPU details\n            print(\"> Running on GPU\", end=' | ')\n            print(\"Num of GPUs: \", ngpu)\n            device='GPU'\n        else:\n            # If no GPUs are available, use CPU\n            print(\"> Running on CPU\")\n            strategy = tf.distribute.get_strategy()\n            device='CPU'\n    return strategy, device, tpu","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.978375Z","iopub.execute_input":"2024-06-06T03:04:23.978884Z","iopub.status.idle":"2024-06-06T03:04:23.994041Z","shell.execute_reply.started":"2024-06-06T03:04:23.97882Z","shell.execute_reply":"2024-06-06T03:04:23.992696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize GPU/TPU/TPU-VM\nstrategy, CFG.device, tpu = get_device()\nCFG.replicas = strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.003188Z","iopub.execute_input":"2024-06-06T03:04:24.003623Z","iopub.status.idle":"2024-06-06T03:04:24.015796Z","shell.execute_reply.started":"2024-06-06T03:04:24.00359Z","shell.execute_reply":"2024-06-06T03:04:24.014445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/birdclef-2024'\nGCS_PATH = BASE_PATH","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.01764Z","iopub.execute_input":"2024-06-06T03:04:24.01815Z","iopub.status.idle":"2024-06-06T03:04:24.032121Z","shell.execute_reply.started":"2024-06-06T03:04:24.018106Z","shell.execute_reply":"2024-06-06T03:04:24.030479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_audio_dir = '/kaggle/input/birdclef-2024/test_soundscapes/'\n\ntest_paths = [test_audio_dir+f for f in sorted(os.listdir(test_audio_dir))]\nif len(test_paths)==1:\n    test_audio_dir = '/kaggle/input/birdclef-2024/unlabeled_soundscapes/'\n\n    test_paths = [test_audio_dir+f for f in sorted(os.listdir(test_audio_dir))][:2]\n    \ntest_df = pd.DataFrame(test_paths, columns=['filepath'])\ntest_df['filename'] = test_df.filepath.map(lambda x: x.split('/')[-1].replace('.ogg',''))\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.034181Z","iopub.execute_input":"2024-06-06T03:04:24.035509Z","iopub.status.idle":"2024-06-06T03:04:24.069309Z","shell.execute_reply.started":"2024-06-06T03:04:24.035462Z","shell.execute_reply":"2024-06-06T03:04:24.067795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.io.gfile.exists(test_df.filepath.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.071458Z","iopub.execute_input":"2024-06-06T03:04:24.071999Z","iopub.status.idle":"2024-06-06T03:04:24.081755Z","shell.execute_reply.started":"2024-06-06T03:04:24.071956Z","shell.execute_reply":"2024-06-06T03:04:24.080407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_audio(filepath, sr=32000, normalize=True):\n    audio, orig_sr = librosa.load(filepath, sr=None)\n    if sr!=orig_sr:\n        audio = librosa.resample(y, orig_sr, sr)\n    audio = audio.astype('float32').ravel()\n    audio = tf.convert_to_tensor(audio)\n    return audio\n\n@tf.function(jit_compile=True)\ndef MakeFrame(audio, duration=5, sr=32000):\n    frame_length = int(duration * sr)\n    frame_step = int(duration * sr)\n    chunks = tf.signal.frame(audio, frame_length, frame_step, pad_end=True)\n    return chunks","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.083696Z","iopub.execute_input":"2024-06-06T03:04:24.084157Z","iopub.status.idle":"2024-06-06T03:04:24.096993Z","shell.execute_reply.started":"2024-06-06T03:04:24.084124Z","shell.execute_reply":"2024-06-06T03:04:24.095596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_audio(row):\n    # Caption for viz\n    caption = f'Id: {row.filename}'\n    # Read audio file\n    audio = load_audio(row.filepath)\n    # Keep fixed length audio\n    audio = audio[:CFG.audio_len]\n    # Display audio\n    print(\"# Audio:\")\n    display(ipd.Audio(audio.numpy(), rate=CFG.sample_rate))\n    print('# Visualization:')\n    plt.figure(figsize=(12, 3))\n    plt.title(caption)\n    # Waveplot\n    lid.waveshow(audio.numpy(),\n                 sr=CFG.sample_rate,)\n                 \n    plt.xlabel('');\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.099953Z","iopub.execute_input":"2024-06-06T03:04:24.100615Z","iopub.status.idle":"2024-06-06T03:04:24.114742Z","shell.execute_reply.started":"2024-06-06T03:04:24.100572Z","shell.execute_reply":"2024-06-06T03:04:24.113534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display_audio(test_df.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.116782Z","iopub.execute_input":"2024-06-06T03:04:24.117249Z","iopub.status.idle":"2024-06-06T03:04:24.125743Z","shell.execute_reply.started":"2024-06-06T03:04:24.117209Z","shell.execute_reply":"2024-06-06T03:04:24.124329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n# Directory of checkpoint\nCKPT_DIR = '/kaggle/input/birdclef2024training'\n\n# Get file paths of all trained models in the directory\nCKPT_PATHS = sorted([x for x in glob(f'{CKPT_DIR}/fold-*keras')])\nprint(\"Checkpoints: \", CKPT_PATHS)\n\n\n# Define a writable directory\nWRITABLE_DIR = '/kaggle/working/models/'\n\n# Create the writable directory if it does not exist\nif not os.path.exists(WRITABLE_DIR):\n    os.makedirs(WRITABLE_DIR)\n\n\n# Copy the model files to the writable directory\nfor ckpt_path in CKPT_PATHS:\n    shutil.copy(ckpt_path, WRITABLE_DIR)\n\n# Update the checkpoint paths to the writable directory\nCKPT_PATHS = sorted([f'{WRITABLE_DIR}/{os.path.basename(x)}' for x in glob(f'{CKPT_DIR}/fold-*keras')])\n\n# Load all the models in memory to speed up\nCKPTS = [tf.keras.models.load_model(x, compile=False) for x in tqdm(CKPT_PATHS, desc=\"Loading ckpts \")]\n# Num of ckpt to use\nNUM_CKPTS = 1\n\n# Submit or Interactive mode\n#SUBMIT = pd.read_csv('/kaggle/input/birdclef-2024/sample_submission.csv').shape[0] != 3","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.127595Z","iopub.execute_input":"2024-06-06T03:04:24.128067Z","iopub.status.idle":"2024-06-06T03:04:30.5591Z","shell.execute_reply.started":"2024-06-06T03:04:24.128035Z","shell.execute_reply":"2024-06-06T03:04:30.557683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start stopwatch\ntick = time.time()\n\n# Initialize empty list to store ids\nids = []\n# Initialize empty array to store predictions\npreds = np.empty(shape=(0, 182), dtype='float32')\n\n# Iterate over each audio file in the test dataset\nfor filepath in tqdm(test_df.filepath.tolist(), 'test '):\n    # Extract the filename without the extension\n    filename = filepath.split('/')[-1].replace('.ogg','')\n    \n    # Load audio from file and create audio frames, each recording will be a batch input\n    audio = load_audio(filepath)\n    chunks = MakeFrame(audio)\n    \n    # Predict bird species for all frames in a recording using all trained models\n    chunk_preds = np.zeros(shape=(len(chunks), 182), dtype=np.float32)\n    for model in CKPTS[:NUM_CKPTS]:\n        # Get the model's predictions for the current audio frames\n        rec_preds = model(chunks, training=False).numpy()\n        # Ensemble all prediction with average\n        chunk_preds += rec_preds/len(CKPTS)\n    \n    # Create a ID for each frame in a recording using the filename and frame number\n    rec_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(chunks))]\n    \n    # Concatenate the ids\n    ids += rec_ids\n    # Concatenate the predictions\n    preds = np.concatenate([preds, chunk_preds], axis=0)\n    \n# Stop stopwatch\ntock = time.time()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:30.561633Z","iopub.execute_input":"2024-06-06T03:04:30.562327Z","iopub.status.idle":"2024-06-06T03:04:37.045852Z","shell.execute_reply.started":"2024-06-06T03:04:30.562281Z","shell.execute_reply":"2024-06-06T03:04:37.044727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.047795Z","iopub.execute_input":"2024-06-06T03:04:37.048213Z","iopub.status.idle":"2024-06-06T03:04:37.056069Z","shell.execute_reply.started":"2024-06-06T03:04:37.04818Z","shell.execute_reply":"2024-06-06T03:04:37.054545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit prediction\npred_df = pd.DataFrame(ids, columns=['row_id'])\npred_df.loc[:, CFG.class_names] = preds\npred_df.to_csv('submission2.csv',index=False)\npred_df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.057817Z","iopub.execute_input":"2024-06-06T03:04:37.058303Z","iopub.status.idle":"2024-06-06T03:04:37.260903Z","shell.execute_reply.started":"2024-06-06T03:04:37.058259Z","shell.execute_reply":"2024-06-06T03:04:37.259556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 合并数据","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 读取两个CSV文件\ndf1 = pd.read_csv('/kaggle/working/submission1.csv')\ndf2 = pd.read_csv('/kaggle/working/submission2.csv')\n\n# 计算新的数据框（排除表头）\nnew_df = df1.iloc[:, 1:] * 0.8 + df2.iloc[:, 1:] * 0.2\n\n# 将表头重新加入新的数据框\nnew_df.insert(0, df1.columns[0], df1[df1.columns[0]])\n\n# 保存新的数据框到CSV文件\nnew_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.372588Z","iopub.execute_input":"2024-06-06T03:04:37.372972Z","iopub.status.idle":"2024-06-06T03:04:37.409119Z","shell.execute_reply.started":"2024-06-06T03:04:37.37294Z","shell.execute_reply":"2024-06-06T03:04:37.407778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_time = (tock-tick)*550 # ~1100 recording on the test data\n# sub_time = time.gmtime(sub_time)\n# sub_time = time.strftime(\"%H hr: %M min : %S sec\", sub_time)\n# print(f\">> Time for submission: ~ {sub_time}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.505683Z","iopub.status.idle":"2024-06-06T03:04:37.50617Z","shell.execute_reply.started":"2024-06-06T03:04:37.50596Z","shell.execute_reply":"2024-06-06T03:04:37.505979Z"},"trusted":true},"execution_count":null,"outputs":[]}]}