{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"},{"sourceId":1664376,"sourceType":"datasetVersion","datasetId":985270},{"sourceId":5181249,"sourceType":"datasetVersion","datasetId":3012199},{"sourceId":8108072,"sourceType":"datasetVersion","datasetId":4789213},{"sourceId":8319412,"sourceType":"datasetVersion","datasetId":4941521},{"sourceId":8478505,"sourceType":"datasetVersion","datasetId":5056677},{"sourceId":8605414,"sourceType":"datasetVersion","datasetId":5149186}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":72.272366,"end_time":"2024-05-27T08:24:12.863444","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-27T08:23:00.591078","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"087aee61943640ff866fad504d3bb8b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2412ab76a24d443693ab5c99798255d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3051ba21b6bb4960912b45a267d7954e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b524d1526854b07a9cbd17a164389ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3051ba21b6bb4960912b45a267d7954e","placeholder":"‚Äã","style":"IPY_MODEL_087aee61943640ff866fad504d3bb8b7","value":""}},"603297b6cf5a4516b17db45b449d8bcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee52a129532428f97b4ffa466195640","placeholder":"‚Äã","style":"IPY_MODEL_98758643ec6f4277946a0b2523b33a62","value":" 0/0 [00:00&lt;?, ?it/s]"}},"7de4c22f5bde4876bd7045b85b99ed48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b524d1526854b07a9cbd17a164389ac","IPY_MODEL_919bacdd323e48c4a80b2ef6b3bdc060","IPY_MODEL_603297b6cf5a4516b17db45b449d8bcd"],"layout":"IPY_MODEL_85db54c088da49578b1a07af47f9565e"}},"85db54c088da49578b1a07af47f9565e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919bacdd323e48c4a80b2ef6b3bdc060":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2412ab76a24d443693ab5c99798255d6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd98675913fb42bca53f7133abd10dae","value":0}},"98758643ec6f4277946a0b2523b33a62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aee52a129532428f97b4ffa466195640":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd98675913fb42bca53f7133abd10dae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\"> 1 | Installing Libraries </p>","metadata":{"papermill":{"duration":0.023488,"end_time":"2024-05-27T08:23:03.890039","exception":false,"start_time":"2024-05-27T08:23:03.866551","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n    !pip install /kaggle/input/onnxruntime/humanfriendly-10.0-py2.py3-none-any.whl --no-index --find-links /kaggle/input/onnxruntime\n    !pip install /kaggle/input/onnxruntime/coloredlogs-15.0.1-py2.py3-none-any.whl --no-index --find-links /kaggle/input/onnxruntime\n    !pip install /kaggle/input/onnxruntime/onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl --no-index --find-links /kaggle/input/onnxruntime","metadata":{"papermill":{"duration":47.930075,"end_time":"2024-05-27T08:23:51.84393","exception":false,"start_time":"2024-05-27T08:23:03.913855","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:56:27.764741Z","iopub.execute_input":"2024-06-09T06:56:27.765158Z","iopub.status.idle":"2024-06-09T06:57:15.528017Z","shell.execute_reply.started":"2024-06-09T06:56:27.765124Z","shell.execute_reply":"2024-06-09T06:57:15.526497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">2 | Importing Libraries </p>","metadata":{"papermill":{"duration":0.025691,"end_time":"2024-05-27T08:23:51.894478","exception":false,"start_time":"2024-05-27T08:23:51.868787","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport glob\nimport time\nimport shutil\nimport random\nimport ast\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport onnx\nimport onnxruntime as ort\nimport wandb\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom tqdm.notebook import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom torch.cuda import amp\nimport torch\nprint(f\"pytorch version is {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.cuda import amp\n\nisTrain = False\nname = 'bird2024exp1057'\n\nimport torchvision\nfrom torchvision.transforms import v2 as transforms\n\nimport librosa\nimport torchaudio\nimport torchaudio.transforms as audioT\n\nimport timm","metadata":{"papermill":{"duration":13.435679,"end_time":"2024-05-27T08:24:05.355498","exception":false,"start_time":"2024-05-27T08:23:51.919819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:57:32.315963Z","iopub.execute_input":"2024-06-09T06:57:32.316419Z","iopub.status.idle":"2024-06-09T06:57:43.230528Z","shell.execute_reply.started":"2024-06-09T06:57:32.316386Z","shell.execute_reply":"2024-06-09T06:57:43.228981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">3 | Configuration Class </p>\n\n","metadata":{"papermill":{"duration":0.026074,"end_time":"2024-05-27T08:24:05.406693","exception":false,"start_time":"2024-05-27T08:24:05.380619","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.024724,"end_time":"2024-05-27T08:24:05.457874","exception":false,"start_time":"2024-05-27T08:24:05.43315","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class config:\n    dir = \"/kaggle/input/birdclef-2024/\"\n\n\n    wave_path = \"original_waves/second_30/\"\n\n    model_name = 'tf_efficientnet_b0'\n\n    pool_type = 'avg'\n\n    \n    train_duration = 30 \n    slice_duration = 5 \n\n    test_duration = 5\n\n    train_drop_duration = 1\n    \n    # spectrogram parameters\n    sr = 32000\n    fmin = 20\n    fmax = 15000\n\n    n_mels = 128\n    n_fft = n_mels*8\n    size_x = 512\n    \n    hop_length = int(sr*slice_duration / size_x)\n    test_hop_length = int(sr*test_duration / size_x)\n    \n    bins_per_octave = 12\n\n    nfolds = 5\n    inference_folds = [4]\n    \n    enable_amp = True\n    train_batchsize = 32\n    valid_batchsize = 1\n\n    # loss_type = \"BCEWithLogitsLoss\"\n    loss_type = \"BCEFocalLoss\"\n\n    #Ë∞ÉÊï¥Â≠¶‰π†ÁéáÔºåÂèòÂ§ßÔºåÊî∂ÊïõÂø´‰∏ÄÁÇπ\n    lr = 2.0e-04 \n\n\n    optimizer='adan'\n    weight_decay = 1.0e-03  #Êõ¥ÊîπËøáÊãüÂêà2\n    es_patience =  5\n    deterministic = True\n    enable_amp = True\n\n    max_epoch = 9\n    aug_epoch = 7   #Êï∞ÊçÆÂ¢ûÂº∫\n    \n\n    useSecondary =True\n    #ÁΩÆ‰ø°Â∫¶\n    secondary_label_value = 0.6\n    #ÂÜ≥ÂÆöÊòØÂê¶ÂØπÊï∞ÊçÆËøõË°åËøáÈááÊ†∑„ÄÇÂ¶ÇÊûúËÆæÁΩÆ‰∏∫ TrueÔºåË°®Êòé‰Ω†ÊâìÁÆóÂ¢ûÂä†Â∞ëÊï∞Á±ªÊ†∑Êú¨ÁöÑÊï∞ÈáèÔºå‰ª•Ê≠§Êù•ÂáèÂ∞ëÁ±ªÂà´‰∏çÂπ≥Ë°°ÁöÑÈóÆÈ¢ò„ÄÇ\n    oversample =True\n    oversample_threthold = 5\n    \n    seed = 42\n\n    wandb = True\n\n    ###augmentation flags   Èü≥È¢ëÂ¢ûÂº∫ÂèÇÊï∞ËÆæÁΩÆ\n    aug_noise            = 0.\n    aug_gain             = 0.0\n    aug_wave_pitchshift  = 0.0\n    aug_wave_shift       = 0.\n\n    aug_spec_xymasking   = 0.\n    aug_spec_coarsedrop  = 0.\n    aug_spec_hflip       = 0.\n\n    ##mixup param\n    aug_wave_mixup       = 1.0\n    aug_spec_mixup       = 0.1\n    aug_spec_mixup_prob  = 0.5 \n    alpha=0.96\n\n    smoothing_value      = 0.0\n    # spec_mix_mask_percent = 20\n    \ncfg = config()\n\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n\nprint(device)","metadata":{"papermill":{"duration":0.045294,"end_time":"2024-05-27T08:24:05.579365","exception":false,"start_time":"2024-05-27T08:24:05.534071","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:57:58.934838Z","iopub.execute_input":"2024-06-09T06:57:58.935282Z","iopub.status.idle":"2024-06-09T06:57:58.949432Z","shell.execute_reply.started":"2024-06-09T06:57:58.935248Z","shell.execute_reply":"2024-06-09T06:57:58.948287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">4 | Data Augmentation Pipeline For Training </p>","metadata":{"papermill":{"duration":0.024909,"end_time":"2024-05-27T08:24:05.629426","exception":false,"start_time":"2024-05-27T08:24:05.604517","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if isTrain== True:\n#Â§ö‰∏™Êï∞ÊçÆÂ¢ûÂº∫Êìç‰Ωú\n    normal_augment = Compose([\n        OneOf([\n            Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n            GainTransition(min_gain_in_db=-24.0, max_gain_in_db=6.0,\n                           min_duration=0.2, max_duration=6.0,  p=1.0)\n        ], p=cfg.aug_gain),\n        \n        OneOf([\n            AddGaussianNoise(p=1),\n            AddColorNoise(p=1, min_snr_db=5, max_snr_db=20, min_f_decay=-3.01, max_f_decay=-3.01)\n        ],p=cfg.aug_noise),\n\n    \n        PitchShift(min_semitones=-1, max_semitones=1, p=cfg.aug_wave_pitchshift),\n        Shift(p=cfg.aug_wave_shift)\n    ])\n    alb_transform = [\n        albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n                                 mask_x_length=cfg.size_x//30, mask_y_length=cfg.n_mels//30,\n                                 fill_value=0, mask_fill_value=0, p=cfg.aug_spec_xymasking),\n        albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=cfg.aug_spec_coarsedrop),\n        albumentations.HorizontalFlip(p=cfg.aug_spec_hflip)    \n    ]\n    albumentations_augment = albumentations.Compose(alb_transform)","metadata":{"papermill":{"duration":0.041072,"end_time":"2024-05-27T08:24:05.746803","exception":false,"start_time":"2024-05-27T08:24:05.705731","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:03.577425Z","iopub.execute_input":"2024-06-09T06:58:03.578198Z","iopub.status.idle":"2024-06-09T06:58:03.588759Z","shell.execute_reply.started":"2024-06-09T06:58:03.578157Z","shell.execute_reply":"2024-06-09T06:58:03.587595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">5 |  Mixup Data Augmentation Function </p>\n","metadata":{"papermill":{"duration":0.024922,"end_time":"2024-05-27T08:24:05.797788","exception":false,"start_time":"2024-05-27T08:24:05.772866","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def mixup(data, targets, alpha, mode=\"same_wave\"):\n    \n    if mode == \"same_wave\":\n        data = torch.tensor(data)\n        indices = torch.randperm(data.size(0))\n        shuffled_data = data[indices]\n\n        lam = np.random.beta(alpha, alpha)\n        new_data = data * lam + shuffled_data * (1 - lam)\n        return new_data.numpy()\n     #‰øùËØÅÊï∞ÊçÆ‰ª•ÂèäÊ†áÁ≠æÈÉΩÊúâÊ≥õÂåñ   \n    elif mode == \"other_wave\":\n        indices = torch.randperm(data.size(0))\n        shuffled_data = data[indices]\n        shuffled_targets = targets[indices]\n    \n        lam = np.random.beta(alpha, alpha)\n        new_data = data * lam + shuffled_data * (1 - lam)\n        new_targets = targets * lam + shuffled_targets * (1 - lam)\n    \n        return new_data, new_targets","metadata":{"papermill":{"duration":0.040647,"end_time":"2024-05-27T08:24:05.864611","exception":false,"start_time":"2024-05-27T08:24:05.823964","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:06.518177Z","iopub.execute_input":"2024-06-09T06:58:06.518619Z","iopub.status.idle":"2024-06-09T06:58:06.528057Z","shell.execute_reply.started":"2024-06-09T06:58:06.518585Z","shell.execute_reply":"2024-06-09T06:58:06.526729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">6 | Spectral Mixup Function</p>\n\n\n\n","metadata":{"papermill":{"duration":0.024581,"end_time":"2024-05-27T08:24:05.914281","exception":false,"start_time":"2024-05-27T08:24:05.8897","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.027032,"end_time":"2024-05-27T08:24:05.966477","exception":false,"start_time":"2024-05-27T08:24:05.939445","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if isTrain== True:\n    spec_xymasking = albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n                                              mask_x_length=cfg.size_x // 10, mask_y_length=cfg.n_mels // 10,\n                                              fill_value=0, mask_fill_value=0, p=1)\n\ndef spec_mixup(data, targets):\n    type = data.dtype\n\n    #Âè™ÊòØÊîπÂèòÈ°∫Â∫èÔºå‰∏çÊîπÂèòÂØπÂ∫îÂÖ≥Á≥ª\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_targets = targets[indices]\n\n    data = np.array(data)\n    data_transposed = np.transpose(data, (2, 3, 1, 0))\n    data_transposed = spec_xymasking(image=data_transposed)[\"image\"]\n    data_transposed = np.transpose(data_transposed, (3, 2, 0, 1))  \n\n    #Â∑ÆÂºÇ‰∏ç‰∏∫0ÁöÑ‰ΩçÁΩÆÂú®Êé©Á†Å‰∏≠‰∏∫1ÔºåË°®Á§∫Êï∞ÊçÆË¢´ÊîπÂèòÔºõÂè™Ê∑∑ÂêàË¢´Êé©Á†ÅË¶ÜÁõñÁöÑÊï∞ÊçÆÁÇπ\n    diff = data - data_transposed\n    mask = (diff != 0).astype(int)\n\n    shuffled_data_masked = (shuffled_data * mask)\n\n    new_data = torch.tensor(data_transposed, dtype=type) + torch.tensor(shuffled_data_masked, dtype=type)\n\n    lam = mask.sum() / len(data) / (cfg.n_mels*cfg.size_x)\n    new_targets = targets * (1-lam) + shuffled_targets *lam\n\n    return new_data, new_targets","metadata":{"papermill":{"duration":0.042092,"end_time":"2024-05-27T08:24:06.084224","exception":false,"start_time":"2024-05-27T08:24:06.042132","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:10.954012Z","iopub.execute_input":"2024-06-09T06:58:10.955175Z","iopub.status.idle":"2024-06-09T06:58:10.967059Z","shell.execute_reply.started":"2024-06-09T06:58:10.955066Z","shell.execute_reply":"2024-06-09T06:58:10.96588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">7 | Mel Spectrogram Generation </p>\n\n","metadata":{"papermill":{"duration":0.02796,"end_time":"2024-05-27T08:24:06.137985","exception":false,"start_time":"2024-05-27T08:24:06.110025","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#ËΩ¨Êç¢‰∏∫MelÈ¢ëË∞±Ë°®Á§∫\nspec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels,f_min=cfg.fmin,f_max=cfg.fmax,mel_scale='slaney',center=True, pad_mode='reflect'\n).to(device)\n#ÊµãËØïÈõÜ\nvalid_spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.test_hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels,f_min=cfg.fmin,f_max=cfg.fmax,mel_scale='slaney',center=True, pad_mode='reflect'\n).to(device)\n#ËÆ≠ÁªÉÂ±Ç\ntest_spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.test_hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels,f_min=cfg.fmin,f_max=cfg.fmax,mel_scale='slaney',center=True, pad_mode='reflect'\n).cpu()","metadata":{"papermill":{"duration":0.181583,"end_time":"2024-05-27T08:24:06.34538","exception":false,"start_time":"2024-05-27T08:24:06.163797","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:14.987688Z","iopub.execute_input":"2024-06-09T06:58:14.988151Z","iopub.status.idle":"2024-06-09T06:58:15.118213Z","shell.execute_reply.started":"2024-06-09T06:58:14.988117Z","shell.execute_reply":"2024-06-09T06:58:15.117197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">8 | Data Preparation Steps</p>\n\n\n \n","metadata":{"papermill":{"duration":0.024773,"end_time":"2024-05-27T08:24:06.395921","exception":false,"start_time":"2024-05-27T08:24:06.371148","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Â§ÑÁêÜÊ†áÁ≠æ„ÄÅËØÜÂà´ÂíåÂà†Èô§ÈáçÂ§çÁöÑÊñá‰ª∂Âêç\nsample_submission = pd.read_csv(cfg.dir+\"sample_submission.csv\")\nLABELS = list(sample_submission.set_index(\"row_id\").columns)\nLABELS[:5]\ntrain_csv = pd.read_csv(cfg.dir+\"train_metadata.csv\")\ntrain_csv['new_target'] = train_csv['primary_label'] + ' ' + train_csv['secondary_labels'].map(lambda x: ' '.join(ast.literal_eval(x)))\ntrain_csv['len_new_target'] =train_csv['new_target'].map(lambda x: len(x.split()))\ntrain_csv[\"len_new_target\"].value_counts().plot(kind=\"bar\", figsize=(4,2))\ntrain_csv[\"filename_tmp\"] = train_csv[\"filename\"].map(lambda x:x.split(\"/\")[1][:-4])\nduplicated_filenames = train_csv[\"filename_tmp\"].value_counts()[train_csv[\"filename_tmp\"].value_counts() > 1].index\ntrain_csv = train_csv[~train_csv[\"filename_tmp\"].isin(duplicated_filenames)]\ntrain_csv = train_csv.reset_index(drop=True)","metadata":{"papermill":{"duration":0.945215,"end_time":"2024-05-27T08:24:07.431523","exception":false,"start_time":"2024-05-27T08:24:06.486308","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:18.617571Z","iopub.execute_input":"2024-06-09T06:58:18.61871Z","iopub.status.idle":"2024-06-09T06:58:19.513717Z","shell.execute_reply.started":"2024-06-09T06:58:18.618672Z","shell.execute_reply":"2024-06-09T06:58:19.512526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\"> 9 | BirdCLEF Dataset Preparation </p>\n\n","metadata":{"papermill":{"duration":0.026002,"end_time":"2024-05-27T08:24:07.483224","exception":false,"start_time":"2024-05-27T08:24:07.457222","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BirdCLEF_Dataset(torch.utils.data.Dataset):\n    #augmentation ÊòØÂê¶Â∫îÁî®Êï∞ÊçÆÂ¢ûÂº∫;ÊòØÂê¶ÁúüÁöÑÊúâÈááÁî®Ôºü\n    def __init__(self, df, augmentation=False, mode='train'):\n        if mode == 'train':\n            self.df = df.reset_index(drop=True)\n        elif mode == 'valid':\n            self.df = df.reset_index(drop=True)\n        else:\n            self.df = df\n        self.mode = mode\n        self.augmentation = augmentation\n    \n    def __len__(self):\n        return len(self.df)\n#ËßÑËåÉÂåñÂ§ÑÁêÜÔºåÊï∞ÊçÆÂú®„Äê0,1„Äë‰πãÈó¥\n    def normalize(self, x):\n        valid_values = x[x != float('-inf')]\n        mean_value = np.mean(valid_values)\n        x[x == float('-inf')] = mean_value\n        \n\n        x = x - x.min()\n        x = x / x.max()\n        return x\n#Á°Æ‰øùÈü≥È¢ëÈïøÂ∫¶Á¨¶ÂêàË¶ÅÊ±Ç\n    def wave_tile_and_cutoff(self, data):\n      \n        drop_duration = cfg.sr*cfg.train_drop_duration\n        use_duration  = cfg.sr*cfg.train_duration\n        \n        if len(data[0]) > drop_duration: \n            data = data[:,drop_duration:]\n\n        if len(data[0]) < use_duration:\n            iter = 1 + (use_duration) // len(data[0])\n            data = np.tile(data, (1, iter))\n\n        data = data[:,:use_duration]\n        return data\n#ÈÅøÂÖçËøáÊãüÂêà\n    def label_smoothing(self, idx, target):\n    \n        secondary_target = target * cfg.secondary_label_value\n    \n        out_of_target_noise_intensity = cfg.smoothing_value/(len(LABELS)-1) \n        out_of_target_noise_array = torch.ones(target.shape) * out_of_target_noise_intensity\n        \n        secondary_target_with_noise = secondary_target + out_of_target_noise_array\n        secondary_target_with_noise = torch.clip(secondary_target_with_noise, min=0, max=cfg.secondary_label_value)\n    \n        primary_target = np.isin(LABELS, self.df.loc[idx, \"primary_label\"]).astype(int)\n        primary_target = torch.tensor(primary_target, dtype=torch.float32)\n\n        primary_and_secondary_target_with_noise = primary_target + secondary_target_with_noise\n        new_target = torch.clip(primary_and_secondary_target_with_noise, min=0, max=1)\n    \n        new_target = new_target - primary_target * cfg.smoothing_value\n    \n        return new_target\n\n    \n    def __getitem__(self, idx):\n#ËÆ≠ÁªÉÈõÜ\n        if self.mode == 'train':\n\n          \n            if cfg.useSecondary == True:\n                target = np.isin(LABELS, self.df.loc[idx, \"new_target\"].split()).astype(int)\n            else:\n                target = np.isin(LABELS, self.df.loc[idx, \"primary_label\"].split()).astype(int)\n            target = torch.tensor(target, dtype=torch.float32)\n          \n            target = self.label_smoothing(idx, target)\n            \n            fileID = self.df.loc[idx, 'fileID'] \n            \n            path = f\"{cfg.wave_path}{fileID}.npy\"\n            wave = np.load(path)\n            \n\n      \n            wave = self.wave_tile_and_cutoff(data=wave)\n\n            \n            input_duration = cfg.sr * cfg.slice_duration\n            \n            \n            if self.augmentation == True:\n               \n                if cfg.aug_wave_mixup > np.random.random():\n                    #train_duration -> slice_duration\n                    wave_reshape = wave.reshape(-1, input_duration)\n                    wave = mixup(data=wave_reshape, targets=target, alpha=cfg.alpha, mode=\"same_wave\")\n                    wave = wave[:1,:]\n                else:\n                    wave = wave[:, :input_duration]\n                \n     \n                wave = normal_augment(samples=wave, sample_rate=cfg.sr)\n\n    \n                wave = torch.tensor(wave).to(device)\n                mel_spec = spec_layer(wave)\n                mel_spec = np.array(mel_spec.cpu())\n\n                mel_spec = np.log(mel_spec)\n                for i in range(len(mel_spec)):\n                    mel_spec[i] = self.normalize(mel_spec[i])\n                mel_spec = torch.tensor(mel_spec)\n                mel_spec = mel_spec[:,:,:cfg.size_x]\n\n     \n                mel_spec = np.array(mel_spec.cpu())\n                mel_spec = np.transpose(mel_spec, (1, 2, 0))                \n                mel_spec = albumentations_augment(image=mel_spec)[\"image\"]\n                mel_spec = np.transpose(mel_spec, (2, 0, 1))\n\n\n                \n            else:\n                wave = wave[:, :input_duration]\n                \n                wave = torch.tensor(wave).to(device)\n                mel_spec = spec_layer(wave)\n                mel_spec = np.array(mel_spec.cpu())\n\n                mel_spec = np.log(mel_spec)\n\n                for i in range(len(mel_spec)):\n                    mel_spec[i] = self.normalize(mel_spec[i])\n                    \n\n                mel_spec = torch.tensor(mel_spec)\n                mel_spec = mel_spec[:,:,:cfg.size_x]\n\n            \n            mel_spec = torch.tensor(mel_spec)\n\n            \n            return mel_spec, target\n#È™åËØÅÈõÜ  Áî®‰∫éËØÑ‰º∞Ê®°ÂûãÁöÑÊÄßËÉΩÔºå‰∏çÈúÄË¶ÅÊï∞ÊçÆÂ¢ûÂº∫\n        elif self.mode == 'valid':\n            \n\n            if cfg.useSecondary == True:\n                target = np.isin(LABELS, self.df.loc[idx, \"new_target\"].split()).astype(int)\n            else:\n                target = np.isin(LABELS, self.df.loc[idx, \"primary_target\"].split()).astype(int)\n            target = torch.tensor(target, dtype=torch.float32)\n            \n            fileID = self.df.loc[idx, 'fileID'] \n            \n            path = f\"{cfg.wave_path}{fileID}.npy\"\n            wave = np.load(path)\n\n            wave = self.wave_tile_and_cutoff(data=wave)\n\n            input_duration = cfg.sr*cfg.test_duration\n            wave_reshape = wave.reshape(-1, input_duration)\n\n            wave_reshape = torch.tensor(wave_reshape).to(device)\n            mel_specs = valid_spec_layer(wave_reshape)\n            mel_specs = mel_specs.cpu().numpy()\n\n            mel_specs = np.log(mel_specs)\n            for i in range(len(mel_specs)):\n                mel_specs[i] = self.normalize(mel_specs[i])\n            mel_specs = torch.tensor(mel_specs)\n            \n            mel_specs = mel_specs[:,:,:cfg.size_x]\n\n            targets = torch.tile(target, dims=(mel_specs.shape[0],1))\n            return mel_specs, targets\n#ÊµãËØïÈõÜ ‰ΩøÁî®Êú™ËßÅËøáÁöÑÊï∞ÊçÆÊµãËØïÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ\n        elif self.mode == 'test':\n\n            filepath = self.df[idx]\n            wave, _  = torchaudio.load(filepath)\n            wave = wave[:,:60*4*32000]\n\n            wave_reshaped = wave.reshape(-1, 1, cfg.test_duration*cfg.sr)\n            \n            mel_spec = test_spec_layer(wave_reshaped)\n            mel_spec = np.log(mel_spec)\n\n            mel_spec = np.array(mel_spec)\n            for i in range(len(mel_spec)):\n                mel_spec[i] = self.normalize(mel_spec[i])\n            mel_spec = torch.tensor(mel_spec)\n\n            mel_spec = mel_spec[:,:,:cfg.size_x]\n            return mel_spec\n#ÂèØ‰ª•ËØÑ‰º∞Ê®°ÂûãÂØπÊú™ËßÅÊï∞ÊçÆÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊµãËØïÊàñÈ™åËØÅÈò∂ÊÆµ„ÄÇ\n        elif self.mode == 'clean':\n\n            filepath = self.df[idx]\n            wave, _  = torchaudio.load(filepath)\n\n            wave = wave[:, :6*cfg.test_duration*cfg.sr]\n\n            chunk_length = len(wave[0]) // (cfg.test_duration*cfg.sr)\n            \n            wave = wave[:,:chunk_length*cfg.test_duration*cfg.sr]\n\n            wave_reshaped = wave.reshape(-1, 1, cfg.test_duration*cfg.sr)\n            \n            mel_spec = test_spec_layer(wave_reshaped)\n            mel_spec = np.log(mel_spec)\n\n            mel_spec = np.array(mel_spec)\n            for i in range(len(mel_spec)):\n                mel_spec[i] = self.normalize(mel_spec[i])\n            mel_spec = torch.tensor(mel_spec)\n\n            return mel_spec, filepath","metadata":{"papermill":{"duration":0.078512,"end_time":"2024-05-27T08:24:07.588078","exception":false,"start_time":"2024-05-27T08:24:07.509566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T06:58:22.68003Z","iopub.execute_input":"2024-06-09T06:58:22.680454Z","iopub.status.idle":"2024-06-09T06:58:22.725718Z","shell.execute_reply.started":"2024-06-09T06:58:22.680417Z","shell.execute_reply":"2024-06-09T06:58:22.724262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isTrain:\n    print(\"train data\")\n    dataset = BirdCLEF_Dataset(df=train_csv, augmentation=True,  mode=\"train\")\n    data, target = dataset[270]\n    fig, ax = plt.subplots(figsize=(6,4))\n    plt.imshow(data[0], cmap=\"jet\", origin=\"lower\")\n    plt.show()\n    \n    print(\"validation data\")\n    dataset = BirdCLEF_Dataset(df=train_csv, augmentation=True,  mode=\"valid\")\n    data, target = dataset[270]\n    fig, axes = plt.subplots(figsize=(12,8), nrows=len(data), tight_layout=True)\n    for idx, ax in enumerate(axes.ravel()):\n        ax.imshow(data[idx], cmap=\"jet\", origin=\"lower\")","metadata":{"papermill":{"duration":0.040422,"end_time":"2024-05-27T08:24:07.705757","exception":false,"start_time":"2024-05-27T08:24:07.665335","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T07:01:25.445908Z","iopub.execute_input":"2024-06-09T07:01:25.447442Z","iopub.status.idle":"2024-06-09T07:01:25.461563Z","shell.execute_reply.started":"2024-06-09T07:01:25.44739Z","shell.execute_reply":"2024-06-09T07:01:25.460067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">10 | BirdModel : Flexible Pooling Architecture For Bird Sound Classification </p>\n\n\n\n","metadata":{"papermill":{"duration":0.025839,"end_time":"2024-05-27T08:24:07.757093","exception":false,"start_time":"2024-05-27T08:24:07.731254","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BirdModel(torch.nn.Module):\n    def __init__(self, model_name, pretrained, in_channels, num_classes, pool=\"default\"):\n        super().__init__()\n\n        self.pool = pool\n        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        #Êï∞ÂÄº‰∏∫ÂùáÂÄº‰ª•ÂèäÊ†áÂáÜÂ∑Æ\n        if pool == \"default\":\n            self.backbone = timm.create_model(\n                model_name=model_name, pretrained=pretrained,\n                num_classes=0, in_chans=3)\n        #ÈááÁî®Ëá™ÂÆö‰πâÁöÑÂÖ®Â±ÄÊ±†Âåñ\n        else:\n            self.backbone = timm.create_model(\n                model_name=model_name, pretrained=pretrained,\n                num_classes=0, in_chans=3, global_pool=\"\")\n        #Ëé∑ÂèñËæìÂá∫ÁâπÂæÅÊï∞Èáè\n        in_features = self.backbone.num_features\n\n\n\n        self.max_pooling = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1),\n                                               torch.nn.Flatten(start_dim=1, end_dim=-1))\n        self.avg_pooling = torch.nn.Sequential(torch.nn.AdaptiveAvgPool2d(1),\n                                               torch.nn.Flatten(start_dim=1, end_dim=-1))\n        #ÊâπÈáèÂΩí‰∏ÄÂ±ÇÔºåÁ∫øÊÄßÂ±Ç\n        self.both_pooling_neck = torch.nn.Sequential(torch.nn.BatchNorm1d(2*in_features),\n                                                     torch.nn.Linear(in_features=2*in_features, out_features=in_features))\n        \n        self.head = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(in_features),\n            torch.nn.Linear(in_features=in_features, out_features=256),\n            torch.nn.Hardswish(inplace=True),torch.nn.Dropout(0.1),\n            torch.nn.Linear(in_features=256, out_features=len(LABELS))  \n        )\n\n\n\n        self.active = torch.nn.Sigmoid()\n    def forward(self, x):\n        x = x.expand(-1, 3, -1, -1)\n        x = self.normalize(x)\n        x = self.backbone(x)\n\n        if self.pool == \"max\":\n            x = self.max_pooling(x)\n        elif self.pool == \"avg\":\n            x = self.avg_pooling(x)\n        elif self.pool == \"both\":\n            x_max = self.max_pooling(x)\n            x_avg = self.avg_pooling(x)\n            x = x_max + x_avg\n            # x = torch.cat([x_max, x_avg], dim=1)\n            # x = self.both_pooling_neck(x)\n         #Ê±†ÂåñÂêéÁöÑËæìÂá∫Ê®°Âûã‰º†ÈÄíÂà∞Ê®°ÂûãÂàÜÁ±ªÂ§¥ÈÉ®   \n        x = self.head(x)\n        # x = self.active(x)\n        return x","metadata":{"papermill":{"duration":0.048113,"end_time":"2024-05-27T08:24:07.883643","exception":false,"start_time":"2024-05-27T08:24:07.83553","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:50:58.768662Z","iopub.execute_input":"2024-06-07T14:50:58.769054Z","iopub.status.idle":"2024-06-07T14:50:58.781777Z","shell.execute_reply.started":"2024-06-07T14:50:58.769022Z","shell.execute_reply":"2024-06-07T14:50:58.780506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">11 | Stratified k-Fold Cross-Validation and Random Seed Setting üê¶</p>\n\n\n1. **Stratified K-Fold Cross-Validation**:\n   - Stratified K-Fold cross-validation is a technique used to evaluate the performance of a machine learning model. It ensures that each fold of the dataset has approximately the same proportion of samples from each class, which is particularly useful for imbalanced datasets.\n   - `StratifiedKFold` is a class from the scikit-learn library that splits a dataset into K folds while preserving the percentage of samples for each class.\n   - In the `for` loop:\n       - `skf.split(train_csv, train_csv['primary_label'])` splits the dataset (`train_csv`) into train and validation sets for each fold, ensuring that each fold maintains the same distribution of classes as the original dataset.\n       - `train_index` and `valid_index` contain the indices of samples for the training and validation sets for the current fold.\n       - `enumerate(skf.split(...))` iterates over each fold, providing the fold index (`fold`) and the corresponding train/validation indices.\n       - `train_csv.loc[valid_index, 'fold'] = int(fold)` assigns the fold index to the validation samples in the `fold` column of the DataFrame `train_csv`, indicating which fold each sample belongs to.\n\n2. **Random Seed Setting**:\n   - Setting random seeds ensures reproducibility of results in machine learning experiments. It initializes the random number generators with a fixed seed, so the same sequence of random numbers is generated every time the code is run.\n   - `set_random_seed` is a function defined to set the random seed across different random number generators used in the experiment.\n   - Inside the function:\n       - `random.seed(seed)`, `np.random.seed(seed)`, and `os.environ[\"PYTHONHASHSEED\"] = str(seed)` set the random seed for the Python built-in random number generator, NumPy, and hash randomization, respectively.\n       - `torch.manual_seed(seed)` sets the random seed for the PyTorch library for CPU operations.\n       - `torch.cuda.manual_seed(seed)` sets the random seed for GPU operations in PyTorch.\n       - `torch.backends.cudnn.deterministic = deterministic` ensures deterministic behavior of CuDNN (CUDA Deep Neural Network library) for GPU operations in PyTorch, which can affect the performance but ensures reproducibility.\n\n","metadata":{"papermill":{"duration":0.025698,"end_time":"2024-05-27T08:24:07.936261","exception":false,"start_time":"2024-05-27T08:24:07.910563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#ÂàÜÂ±ÇÊäΩÊ†∑ÁöÑKÊäò‰∫§ÂèâÈ™åËØÅÔºåËé∑ÂèñË°åÁ¥¢Âºï\nskf = StratifiedKFold(n_splits=cfg.nfolds, shuffle=True, random_state=cfg.seed)\nfor fold, (train_index, valid_index) in enumerate(skf.split(train_csv, train_csv['primary_label'])):\n    train_csv.loc[valid_index, 'fold'] = int(fold)\n    \n#ÂàÜÁªÑÁªüËÆ° ‰ª•ÂèäËØÑ‰º∞ÂàÜÂ±ÇÊäΩÊ†∑ K Êäò‰∫§ÂèâÈ™åËØÅÊòØÂê¶ÊàêÂäüÂú∞‰øùÊåÅ‰∫ÜÊØè‰∏™ÊäòÂè†‰∏≠Á±ªÂà´ÂàÜÂ∏ÉÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ\nif isTrain:\n    train_csv.groupby(\"fold\", as_index=False)[\"primary_label\"].value_counts()   \n    \n    \ndef set_random_seed(seed: int = 42, deterministic: bool = False):\n    \"\"\"Set seeds\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = deterministic  # type: ignore    ","metadata":{"papermill":{"duration":0.082794,"end_time":"2024-05-27T08:24:08.04628","exception":false,"start_time":"2024-05-27T08:24:07.963486","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:51:04.538613Z","iopub.execute_input":"2024-06-07T14:51:04.539019Z","iopub.status.idle":"2024-06-07T14:51:04.576722Z","shell.execute_reply.started":"2024-06-07T14:51:04.538989Z","shell.execute_reply":"2024-06-07T14:51:04.575372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\"> 12 | BCEFocalLoss: Binary Cross-Entropy Focal Loss üê¶</p>\n\n\n1. **BCEFocalLoss Class**:\n    - This class defines a custom loss function called `BCEFocalLoss` for binary classification tasks.\n    - It inherits from `nn.Module`, indicating that it's a PyTorch module.\n\n2. **Initialization**:\n    - The `__init__` method initializes the loss function with two parameters: `alpha` and `gamma`.\n    - `alpha` (default value: 0.25) controls the balance between positive and negative class samples in the loss calculation.\n    - `gamma` (default value: 2.0) controls the degree of focus on hard-to-classify examples.\n\n3. **Forward Method**:\n    - The `forward` method computes the loss given model predictions (`preds`) and ground truth labels (`targets`).\n    - It first calculates the binary cross-entropy (BCE) loss using `nn.BCEWithLogitsLoss` with the option `reduction='none'` to compute the loss per sample without averaging.\n    - `probas = torch.sigmoid(preds)` computes the sigmoid activation of the model predictions to obtain probabilities.\n\n4. **Focal Loss Components**:\n    - Focal loss introduces two additional components: focal term (`tmp`) and smooth term (`smp`).\n    - `tmp` calculates the focal loss for positive class samples, where the focus is increased for misclassified samples (`(1. - probas)**self.gamma` increases the loss for hard-to-classify examples).\n    - `smp` calculates the focal loss for negative class samples, focusing on correctly classified samples (`probas**self.gamma` increases the loss for hard-to-classify examples).\n    - Both `tmp` and `smp` are multiplied by the BCE loss to incorporate the original loss calculation.\n\n5. **Final Loss Calculation**:\n    - The final loss is calculated as the sum of `tmp` and `smp`, followed by taking the mean over all samples.\n    - This mean loss value is returned as the output of the `forward` method.\n\n","metadata":{"papermill":{"duration":0.025938,"end_time":"2024-05-27T08:24:08.098639","exception":false,"start_time":"2024-05-27T08:24:08.072701","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BCEFocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, preds, targets):\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n        probas = torch.sigmoid(preds)\n\n        \n\n        tmp = targets * self.alpha * (1. - probas)**self.gamma * bce_loss\n        smp = (1. - targets) * probas**self.gamma * bce_loss\n        \n        loss = tmp + smp\n        loss = loss.mean()\n        return loss","metadata":{"papermill":{"duration":0.039605,"end_time":"2024-05-27T08:24:08.164291","exception":false,"start_time":"2024-05-27T08:24:08.124686","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:51:09.748386Z","iopub.execute_input":"2024-06-07T14:51:09.748814Z","iopub.status.idle":"2024-06-07T14:51:09.757526Z","shell.execute_reply.started":"2024-06-07T14:51:09.748782Z","shell.execute_reply":"2024-06-07T14:51:09.755505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">13 | Initialization Function For Training </p>\n\n1. **Model Initialization**:\n   - The function initializes the neural network model using the `BirdModel` class, which is customized for bird sound classification.\n   - It sets parameters such as the model architecture (`model_name`), whether to use pre-trained weights (`pretrained`), number of input channels (`in_channels`), number of output classes (`num_classes`), and pooling type (`pool`).\n\n2. **Optimizer Selection**:\n   - Depending on the configuration (`cfg.optimizer`), the function selects the optimizer for training.\n   - If `cfg.optimizer` is set to `'adan'`, it uses the custom optimizer `Adan` with specific parameters like learning rate (`lr`), betas, and weight decay.\n   - Otherwise, it uses the standard AdamW optimizer from PyTorch with parameters such as learning rate (`lr`) and weight decay.\n\n3. **Learning Rate Scheduler**:\n   - The function initializes a learning rate scheduler using `torch.optim.lr_scheduler.OneCycleLR`.\n   - This scheduler adjusts the learning rate during training, starting from an initial value (`cfg.lr`), and following a one-cycle policy with specified parameters such as the maximum number of epochs (`cfg.max_epoch`), percentage of epochs to increase/decrease learning rate (`pct_start`), and step size (`steps_per_epoch`).\n\n4. **Gradient Scaler (Automatic Mixed Precision)**:\n   - Automatic Mixed Precision (AMP) is a technique that combines single and half-precision floating-point arithmetic to speed up training while maintaining numerical stability.\n   - The function initializes a gradient scaler using `amp.GradScaler` with the option to enable or disable AMP based on the configuration (`cfg.enable_amp`).\n\n5. **Loss Function Initialization**:\n   - Depending on the loss type specified in the configuration (`cfg.loss_type`), the function initializes the loss function.\n   - If `cfg.loss_type` is set to `\"BCEWithLogitsLoss\"`, it uses the binary cross-entropy loss with logits (`torch.nn.BCEWithLogitsLoss`).\n   - If `cfg.loss_type` is set to `\"BCEFocalLoss\"`, it uses the custom focal loss function `BCEFocalLoss` with a specified `alpha` value.\n\n6. **Returning Initialized Components**:\n   - The function returns the initialized model, optimizer, scheduler, scaler, and loss function, all moved to the appropriate device (`device`), typically GPU.\n\n","metadata":{"papermill":{"duration":0.025553,"end_time":"2024-05-27T08:24:08.215738","exception":false,"start_time":"2024-05-27T08:24:08.190185","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def initialization():\n    model = BirdModel(model_name=cfg.model_name, pretrained=True, in_channels=3, num_classes=len(LABELS), pool=cfg.pool_type)\n    \n    if cfg.optimizer=='adan':\n        optimizer = Adan(model.parameters(), lr=cfg.lr, betas=(0.02, 0.08, 0.01), weight_decay=cfg.weight_decay)\n    else:\n        optimizer = torch.optim.AdamW(params=model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer, epochs=cfg.max_epoch,\n        pct_start=0.0, steps_per_epoch=len(train_dataloader),\n        max_lr=cfg.lr, div_factor=25, final_div_factor=4.0e-01\n    )\n    \n    scaler = amp.GradScaler(enabled=cfg.enable_amp)\n    if cfg.loss_type == \"BCEWithLogitsLoss\":\n        loss_func = torch.nn.CrossEntropyLoss()\n    elif cfg.loss_type == \"BCEFocalLoss\":\n        loss_func = BCEFocalLoss(alpha=1)\n    \n    \n\n\n    return model.to(device), optimizer, scheduler, scaler, loss_func.to(device)","metadata":{"papermill":{"duration":0.041677,"end_time":"2024-05-27T08:24:08.283638","exception":false,"start_time":"2024-05-27T08:24:08.241961","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T14:51:14.877655Z","iopub.execute_input":"2024-06-07T14:51:14.878075Z","iopub.status.idle":"2024-06-07T14:51:14.887035Z","shell.execute_reply.started":"2024-06-07T14:51:14.878041Z","shell.execute_reply":"2024-06-07T14:51:14.885739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">14 | Training And Evaluation Functions üê¶</p>\n\n1. **`train_one_loop` Function**:\n   - This function performs one epoch of training.\n   - It iterates through the training data (`dataloader`) and updates the model parameters based on the calculated loss.\n   - Within each iteration:\n     - The data and labels are moved to the appropriate device (`device`).\n     - The gradients are zeroed using `optimizer.zero_grad()` to clear the previous gradients.\n     - Inside the training loop, gradient scaling is applied using AMP (Automatic Mixed Precision) to improve numerical stability and speed up training.\n     - The loss is computed using the specified loss function (`loss_fn`) and backpropagated through the network.\n     - The optimizer's learning rate is adjusted using the scheduler (`scheduler.step()`).\n     - The loss value is accumulated for monitoring training progress.\n   - After processing all batches, the average training loss is calculated and logged (if using Weights & Biases for logging).\n\n2. **`mixup_one_loop` Function**:\n   - This function performs one epoch of training with mixup augmentation.\n   - Mixup is a data augmentation technique that blends pairs of examples and their corresponding labels.\n   - It follows a similar structure to `train_one_loop`, but before feeding the data to the model, it applies mixup augmentation based on a probability threshold (`cfg.aug_spec_mixup_prob`).\n   - Mixup can be applied either on different waveforms (`\"other_wave\"`) or on spectrograms (`\"spec_mixup\"`).\n   - The rest of the process, including loss computation and optimization, remains the same.\n\n3. **`evaluate_validation` Function**:\n   - This function evaluates the model on the validation dataset (`dataloader`) after each epoch of training.\n   - It calculates validation loss and various evaluation metrics such as AUC (Area Under the ROC Curve), F1-score, precision, and more.\n   - Inside the evaluation loop:\n     - The model makes predictions on the validation data.\n     - Predictions are compared with the ground truth labels to compute the evaluation metrics.\n     - The validation loss is computed using the specified loss function.\n   - The function returns the validation loss and evaluation metrics, which can be used for monitoring the model's performance during training.\n\nThese functions collectively handle the training and evaluation process of the bird sound classification model, including data processing, model training, and performance evaluation. Additionally, they provide flexibility in choosing different training strategies such as mixup augmentation and support for monitoring training progress using Weights & Biases.","metadata":{"papermill":{"duration":0.026164,"end_time":"2024-05-27T08:24:08.335485","exception":false,"start_time":"2024-05-27T08:24:08.309321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_one_loop(model, optimizer, scaler, scheduler, dataloader, loss_fn):\n    trainloss = 0; model.train()\n\n    count = 0\n    for idx, (data, label) in enumerate(tqdm(dataloader,leave=False ,desc=\"[train]\")):\n        # label = label.reshape(-1, len(LABELS))\n        \n        data, label = data.to(device), label.to(device)\n        \n        optimizer.zero_grad()\n        with amp.autocast(cfg.enable_amp, dtype=torch.bfloat16):\n        # with amp.autocast(cfg.enable_amp):\n            pred = model.forward(data)\n            loss = loss_fn(pred, label)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n        \n        trainloss += loss.item()\n        # print(idx, loss.item())\n        # if cfg.wandb == True:\n        #     wandb.log({f\"train_loss\": loss.item(), f\"lr\":scheduler.get_lr()[0]})\n        del data, label, loss\n        count += 1\n        # if count == 300:\n        # break\n    trainloss /= len(dataloader)\n    if cfg.wandb == True:\n        wandb.log({f\"train_loss\": trainloss, f\"lr\":scheduler.get_lr()[0]})\n    return model, optimizer, scaler, scheduler, trainloss\n\n\ndef mixup_one_loop(model, optimizer, scaler, scheduler, dataloader, loss_fn):\n    trainloss = 0; model.train()\n\n    count = 0\n    for idx, (data, label) in enumerate(tqdm(dataloader,leave=False ,desc=\"[train]\")):\n        if np.random.random()>cfg.aug_spec_mixup_prob:\n            data, label = mixup(data=data, targets=label, alpha=cfg.alpha, mode=\"other_wave\")\n        else:\n            data, label = spec_mixup(data=data, targets=label)\n        data, label = data.to(device), label.to(device)\n        \n        optimizer.zero_grad()\n        with amp.autocast(cfg.enable_amp, dtype=torch.bfloat16):\n        # with amp.autocast(cfg.enable_amp):\n            pred = model.forward(data)\n            loss = loss_fn(pred, label)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n        \n        trainloss += loss.item()\n        # print(idx, loss.item())\n        # if cfg.wandb == True:\n        #     wandb.log({f\"lr\":scheduler.get_lr()[0]})\n        del data, label, loss\n        count += 1\n        # if count == 300:\n        # break\n    trainloss /= len(dataloader)\n    if cfg.wandb == True:\n        wandb.log({f\"train_loss\": trainloss, f\"lr\":scheduler.get_lr()[0]})\n    return model, optimizer, scaler, scheduler, trainloss\n\nfrom sklearn.metrics import f1_score\ndef evaluate_validation(model, dataloader, loss_fn):\n    validloss=0\n    model.eval()\n\n    preds, trues, targets = [], [], []\n    \n    for idx, (data, label) in enumerate(tqdm(dataloader,leave=False ,desc=\"[valid]\")):\n        # label = label.reshape(-1, len(LABELS))\n\n        d = data[0].unsqueeze(1)\n        label = label[0]\n        \n        d = d.to(device)\n        # with amp.autocast(cfg.enable_amp):\n        pred = model.forward(d)\n\n        preds.extend(pred.detach().cpu())\n        trues.extend(label)\n        targets.extend(label.argmax(axis=1))\n        \n    #======================== metrics ========================#\n    # y_preds = torch.stack(preds)\n    t = torch.stack(preds)\n    t = torch.sigmoid(t)\n    targets = torch.tensor(targets)\n    y_trues = torch.stack(trues)\n\n\n    validloss = loss_fn(torch.stack(preds), torch.stack(trues))\n    #     # print(idx, loss)\n    #     # wandb.log({\"valid_loss\": loss})\n\n    # validloss /= len(dataloader)\n    \n\n\n# ÂÅáËÆæ t ÊòØ‰∏Ä‰∏™ PyTorch Âº†ÈáèÔºåtargets ÊòØÊ†áÁ≠æÁöÑÂàóË°®\n# Â∞Ü targets ËΩ¨Êç¢‰∏∫ PyTorch Âº†Èáè\n\n    targets_tensor = torch.tensor(targets)\n\n    def calculate_f1_at_threshold(y_true, predictions, threshold, average=\"micro\"):\n    # Â∫îÁî®ÈòàÂÄºÂπ∂ËÆ°ÁÆóF1ÂàÜÊï∞\n        binary_predictions = (predictions > threshold).int()\n        return f1_score(y_true, binary_predictions.numpy(), average=average)\n\n# ËÆ°ÁÆó‰∏çÂêåÈòàÂÄº‰∏ãÁöÑF1ÂàÜÊï∞\n    f1_scores = {\n        \"F1_03\": calculate_f1_at_threshold(targets_tensor, t, 0.3),\n        \"F1_05\": calculate_f1_at_threshold(targets_tensor, t, 0.5)\n    }\n\n    # ËÆ°ÁÆóAUCÂíåÁ≤æÁ°ÆÂ∫¶\n    auc = multiclass_auroc(t, targets_tensor, len(LABELS), \"macro\")\n    prec = multiclass_precision(t, targets_tensor, len(LABELS), \"macro\")\n\n     # ËÆ°ÁÆóÂæÆËßÇÂíåÂÆèËßÇÂπ≥ÂùáÁöÑF1ÂàÜÊï∞\n    f1 = multiclass_f1_score(t, targets_tensor, len(LABELS), \"micro\")\n    f1_macro = multiclass_f1_score(t, targets_tensor, len(LABELS), \"macro\")\n\n# ÊâìÂç∞ÁªìÊûú\n    print(f\"AUC (Macro): {auc}\")\n    print(f\"Precision (Macro): {prec}\")\n    print(f\"F1 Score (Micro): {f1}\")\n    print(f\"F1 Score (Macro): {f1_macro}\")\n    for key, value in f1_scores.items():\n        print(f\"{key}: {value}\")\n\n   \n    if cfg.wandb == True:\n        wandb.log({f\"valid_loss\": validloss,\n                   f\"AUC\":auc,\n                   # \"auc_micro\":auc_micro,\n                   \"precision\":prec, \n                   # \"recall\":rec, \n                   # \"accuracy\":acc,\n                   f\"F1\":f1,\n                   \"F1_macro\":f1_macro,\n                   f\"F1 30%\":f1_03,\n                   f\"F1 50%\":f1_05})\n    return validloss, auc, f1, f1_03, f1_05, sk_f1_30, sk_f1_50","metadata":{"papermill":{"duration":0.063951,"end_time":"2024-05-27T08:24:08.425685","exception":false,"start_time":"2024-05-27T08:24:08.361734","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T15:48:27.859167Z","iopub.execute_input":"2024-06-07T15:48:27.859602Z","iopub.status.idle":"2024-06-07T15:48:27.885546Z","shell.execute_reply.started":"2024-06-07T15:48:27.859568Z","shell.execute_reply":"2024-06-07T15:48:27.884129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isTrain == True:\n    tmp_params = dict(vars(config))\n    del tmp_params['__module__'],tmp_params['__dict__'],tmp_params['__weakref__'],tmp_params['__doc__']\n\ndef get_oversampled_df(df):\n    \n    new_df = [df]\n\n    low_sample_birds = df[\"primary_label\"].value_counts()[df[\"primary_label\"].value_counts() < cfg.oversample_threthold].index\n    for bird in low_sample_birds:\n        tmp = df[df[\"primary_label\"] == bird]\n        data_num = len(tmp)\n    \n        tiles = 1 + cfg.oversample_threthold // data_num\n    \n        tile_df = []\n        for i in range(tiles):\n            tile_df.append(tmp)\n    \n        tiled_df = pd.concat(tile_df)\n        piece = tiled_df[data_num:cfg.oversample_threthold]\n        new_df.append(piece)\n    \n    return pd.concat(new_df)","metadata":{"papermill":{"duration":0.042146,"end_time":"2024-05-27T08:24:08.546191","exception":false,"start_time":"2024-05-27T08:24:08.504045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T15:48:35.763836Z","iopub.execute_input":"2024-06-07T15:48:35.764806Z","iopub.status.idle":"2024-06-07T15:48:35.772703Z","shell.execute_reply.started":"2024-06-07T15:48:35.76477Z","shell.execute_reply":"2024-06-07T15:48:35.77149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if isTrain == True:\n    set_random_seed(seed=42)\n    \n    \n    if cfg.wandb == True:\n        wandb.init(project='BirdCLEF_cv_ver2', name=f\"{name}\",\n                   config=tmp_params)\n        \n    # for fold in range(cfg.nfolds):\n    for fold in cfg.inference_folds:\n        train_ = train_csv.loc[train_csv[\"fold\"]!=fold]\n\n        if cfg.oversample == True:\n            train = get_oversampled_df(df=train_)\n        else:\n            train = train_\n        \n        augme_dataset = BirdCLEF_Dataset(df=train, augmentation=True, mode='train')\n        augme_dataloader = torch.utils.data.DataLoader(dataset=augme_dataset, batch_size=cfg.train_batchsize, shuffle=True)\n\n        train_dataset = BirdCLEF_Dataset(df=train, augmentation=False, mode='train')\n        train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=cfg.train_batchsize, shuffle=True)\n        \n        valid = train_csv.loc[train_csv[\"fold\"]==fold]\n        valid_dataset = BirdCLEF_Dataset(df=valid, augmentation=False, mode='valid')\n        valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=cfg.valid_batchsize, shuffle=False)\n    \n        model, optimizer, scheduler, scaler, loss_func =  initialization()\n    \n    \n        best_f1 = 0\n        best_auc = 0\n        best_loss = 1.00000\n        for e in range(cfg.max_epoch):\n            start_time = time.time()\n            if e < cfg.aug_epoch:\n                if cfg.aug_spec_mixup > np.random.random():\n                    model, optimizer, scaler, shcheduler, train_loss = mixup_one_loop(model=model,optimizer=optimizer,scaler=scaler, \n                                                                                          scheduler=scheduler,dataloader=augme_dataloader, loss_fn=loss_func)\n                else:\n                    model, optimizer, scaler, shcheduler, train_loss = train_one_loop(model=model,optimizer=optimizer,scaler=scaler, \n                                                                                          scheduler=scheduler,dataloader=augme_dataloader, loss_fn=loss_func)\n\n            else:\n                model, optimizer, scaler, shcheduler, train_loss = train_one_loop(model=model,optimizer=optimizer,scaler=scaler, \n                                                                                          scheduler=scheduler,dataloader=train_dataloader, loss_fn=loss_func)\n            \n            valid_loss, auc, f1, f1_03, f1_05, sk_f1_30, sk_f1_50 = evaluate_validation(model=model, dataloader=valid_dataloader, loss_fn=loss_func)\n            # print(f\"epoch {e} , train_loss is {train_loss}, valid_loss is {valid_loss}\")\n            \n            if best_loss > valid_loss:\n                end_time = time.time()\n                print(f\"[epoch {str(e).zfill(2)}] AUC{auc: .4f}, F1{f1: .4f}, F1_03{f1_03: .4f}, F1_05{f1_05: .4f}\")\n                print(f\"[epoch {str(e).zfill(2)}] SKF1_03{sk_f1_30: .4f}, SKF1_05{sk_f1_50: .4f}\")\n                print(f\"[epoch {str(e).zfill(2)}] valid_loss {valid_loss: .6f}\")\n                print(f\"[epoch {str(e).zfill(2)}] update loss {best_loss: .6f} --> {valid_loss: .6f} {(end_time - start_time): .1f}[s]\")\n                print(f\"[epoch {str(e).zfill(2)}] update auc score {best_auc: .6f} --> {auc: .6f} {(end_time - start_time): .1f}[s]\")\n                model_name = f'{name}/checkpoint/fold_{fold}_snapshot_epoch_{str(e).zfill(2)}.pth'\n                best_model = model\n                best_loss = valid_loss\n                best_auc = auc\n                best_f1 = f1\n            else:\n                end_time = time.time()\n                print(f\"[epoch {str(e).zfill(2)}] NOT update loss {best_loss: .6f} <-- {valid_loss: .6f} {(end_time - start_time): .1f}[s]\")\n                print(f\"[epoch {str(e).zfill(2)}] NOT update score {best_auc: .6f} <-- {auc: .6f} {(end_time - start_time): .1f}[s]\")\n\n        if cfg.wandb == True:\n            wandb.log({f\"best_loss\": best_loss,\n                       f\"best_f1\": best_f1,\n                       f\"best_auc\":best_auc})\n\n        torch.save(best_model.state_dict(), model_name)\n        \n        del model, best_model\n        gc.collect()\n        torch.cuda.empty_cache()\n        print(\"--\")\n","metadata":{"papermill":{"duration":0.05756,"end_time":"2024-05-27T08:24:08.683435","exception":false,"start_time":"2024-05-27T08:24:08.625875","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-07T15:48:40.873828Z","iopub.execute_input":"2024-06-07T15:48:40.874209Z","iopub.status.idle":"2024-06-07T15:48:40.893806Z","shell.execute_reply.started":"2024-06-07T15:48:40.874179Z","shell.execute_reply":"2024-06-07T15:48:40.892257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">15 | Model Loading For Inference üê¶</p>\n\n1. **Initializing Dictionaries:**\n   - Two dictionaries, `models` and `models_names`, are initialized to store loaded models and their corresponding names, respectively.\n\n2. **Iterating Over Folds:**\n   - The code iterates over each fold for which inference is required (`for fold in cfg.inference_folds:`).\n\n3. **Loading Trained Model:**\n   - The path to the best-performing model checkpoint for the current fold is obtained using `glob.glob`.\n   - The `BirdModel` class is instantiated to create a new model instance with the same architecture as the trained model.\n   - The model's state dictionary is loaded from the saved checkpoint file using `torch.load`.\n   - The loaded model is set to evaluation mode using `model.eval()`.\n\n4. **Storing Loaded Models and Names:**\n   - The loaded model is stored in the `models` dictionary with the fold index as the key.\n   - The name of the ONNX file for the model is generated from the checkpoint file path and stored in the `models_names` dictionary.\n\n5. **Printing Model Path and ONNX Name:**\n   - The path of the loaded model checkpoint file and the corresponding ONNX file name are printed for verification.\n\n","metadata":{"papermill":{"duration":0.025863,"end_time":"2024-05-27T08:24:08.735311","exception":false,"start_time":"2024-05-27T08:24:08.709448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"models = dict()\nmodels_names = dict()\n# for fold in range(cfg.nfolds):\nfor fold in cfg.inference_folds:\n    bestmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.pth\"))[-1]\n\n    print(bestmodel_path)\n    model = BirdModel(model_name=cfg.model_name, pretrained=False, in_channels=1, num_classes=len(LABELS))\n    model.load_state_dict(torch.load(bestmodel_path, map_location=torch.device('cpu')))\n    model = model.eval()\n    models[fold] = model\n\n    models_names[fold] = bestmodel_path.split(\".\")[0]+\".onnx\"\n    print(models_names[fold])","metadata":{"papermill":{"duration":0.614286,"end_time":"2024-05-27T08:24:09.375315","exception":false,"start_time":"2024-05-27T08:24:08.761029","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:00.441884Z","iopub.execute_input":"2024-06-06T03:04:00.442252Z","iopub.status.idle":"2024-06-06T03:04:00.739291Z","shell.execute_reply.started":"2024-06-06T03:04:00.442224Z","shell.execute_reply":"2024-06-06T03:04:00.737987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_audio_dir = f\"{cfg.dir}test_soundscapes/\"\nfile_list = glob.glob(test_audio_dir+\"*.ogg\")\nfile_list = sorted(file_list)\n\n\ntest_dataset = BirdCLEF_Dataset(df=file_list, mode=\"test\")\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                              batch_size=1, \n                                              shuffle=False)\n\ninput_tensor = torch.randn((48, 1, cfg.n_mels, cfg.size_x+1))  # input shape\noutput_names=['output']\ninput_names=[\"x\"]\n\n\n# models_names = []\nmodels_names = dict()\n# for fold in range(cfg.nfolds):\nfor fold in cfg.inference_folds:\n    onnxmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.onnx\"))[-1]\n\n    print(onnxmodel_path)\n\n    models_names[fold] = onnxmodel_path\n    \n    \nonnx_sessions = dict()\n# for fold in range(cfg.nfolds):\nfor fold in cfg.inference_folds:\n\n    onnx_model = onnx.load(models_names[fold])\n    onnx_model_graph = onnx_model.graph\n    onnx_session = ort.InferenceSession(onnx_model.SerializeToString())\n\n    onnx_sessions[fold] = onnx_session    ","metadata":{"papermill":{"duration":0.449231,"end_time":"2024-05-27T08:24:09.902461","exception":false,"start_time":"2024-05-27T08:24:09.45323","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:00.743192Z","iopub.execute_input":"2024-06-06T03:04:00.744411Z","iopub.status.idle":"2024-06-06T03:04:01.037925Z","shell.execute_reply.started":"2024-06-06T03:04:00.744364Z","shell.execute_reply":"2024-06-06T03:04:01.036509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\npredictions = []\nfor data in tqdm(test_dataloader):\n    \n    preds = []\n    \n#     for fold, session in enumerate(onnx_sessions):\n    for fold in cfg.inference_folds:\n        session = onnx_sessions[fold]\n        pred = session.run(output_names, {input_names[0]: data[0].numpy()})[0]\n        \n        pred = torch.sigmoid(torch.tensor(pred))\n        preds.append(pred)\n    preds_per_batch = torch.stack(preds, axis=0).mean(axis=0)\n    \n    predictions.extend(preds_per_batch)\n    \nif len(predictions)>0:\n    predictions = torch.stack(predictions)\nelse:\n    predictions = predictions\nend_time = time.time()\nuse_time = end_time - start_time","metadata":{"papermill":{"duration":0.069935,"end_time":"2024-05-27T08:24:10.05298","exception":false,"start_time":"2024-05-27T08:24:09.983045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:01.04206Z","iopub.execute_input":"2024-06-06T03:04:01.042495Z","iopub.status.idle":"2024-06-06T03:04:01.076097Z","shell.execute_reply.started":"2024-06-06T03:04:01.042464Z","shell.execute_reply":"2024-06-06T03:04:01.074716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family: 'Amiri'; font-size: 3rem; color: Black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: #c9b68b; padding: 20px; border-radius: 20px; border: 7px solid Black; width:95%\">16 | Final Submission üìù</p>\n\n\n","metadata":{"papermill":{"duration":0.025943,"end_time":"2024-05-27T08:24:10.105111","exception":false,"start_time":"2024-05-27T08:24:10.079168","status":"completed"},"tags":[]}},{"cell_type":"code","source":"bird_cols = sample_submission.columns[1:]\ndf = pd.DataFrame(columns=['row_id']+list(bird_cols))\n\n\nrow_list = []\nfor file in file_list:\n    dataname = file.split(\"/\")[-1][:-4]\n    for i in range(int(4*60/5)):\n        row = f\"{dataname}_{(i+1)*5}\"\n        row_list.append(row)\n        \n        \n        \ndf['row_id'] = row_list        \n\nif len(predictions) < 1:\n    pass\nelse:\n    df[bird_cols] = predictions\n    \n    \ndf.to_csv(\"submission1.csv\", index=False)     ","metadata":{"papermill":{"duration":0.055183,"end_time":"2024-05-27T08:24:10.186739","exception":false,"start_time":"2024-05-27T08:24:10.131556","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-06T03:04:01.078034Z","iopub.execute_input":"2024-06-06T03:04:01.078592Z","iopub.status.idle":"2024-06-06T03:04:01.10317Z","shell.execute_reply.started":"2024-06-06T03:04:01.078554Z","shell.execute_reply":"2024-06-06T03:04:01.101673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:01.105134Z","iopub.execute_input":"2024-06-06T03:04:01.105549Z","iopub.status.idle":"2024-06-06T03:04:01.135698Z","shell.execute_reply.started":"2024-06-06T03:04:01.105517Z","shell.execute_reply":"2024-06-06T03:04:01.133995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## another","metadata":{}},{"cell_type":"code","source":"import sys, os\nsys.path.append('/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle')\n!pip install -q /kaggle/input/tensorflow-extra-lib-ds/tensorflow_extra-1.0.2-py3-none-any.whl --no-deps","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:01.137495Z","iopub.execute_input":"2024-06-06T03:04:01.138048Z","iopub.status.idle":"2024-06-06T03:04:23.851124Z","shell.execute_reply.started":"2024-06-06T03:04:01.138Z","shell.execute_reply":"2024-06-06T03:04:23.849563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.get_logger().setLevel('ERROR')\ntf.autograph.set_verbosity(0)\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nfrom glob import glob\nfrom tqdm import tqdm\ntqdm.pandas()\nimport gc\nimport librosa\nimport sklearn\nimport time\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport librosa.display as lid\nimport IPython.display as ipd\n\nimport tensorflow as tf\ntf.config.optimizer.set_jit(True) # enable xla for speed up\nimport tensorflow_io as tfio\nimport tensorflow.keras.backend as K\n\nimport efficientnet.tfkeras as efn\nimport tensorflow_extra as tfe","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.853579Z","iopub.execute_input":"2024-06-06T03:04:23.854124Z","iopub.status.idle":"2024-06-06T03:04:23.874036Z","shell.execute_reply.started":"2024-06-06T03:04:23.854074Z","shell.execute_reply":"2024-06-06T03:04:23.872447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    debug = False\n    verbose = 0\n    \n    device = 'CPU'\n    seed = 42\n    \n    # Input image size and batch size\n    img_size = [128, 384]\n    batch_size = 16\n    infer_bs = 2\n    tta = 1\n    drop_remainder = True\n    \n    # STFT parameters\n    duration = 5 # duration for test\n    train_duration = 10\n    sample_rate = 32000\n    downsample = 1\n    audio_len = duration*sample_rate\n    nfft = 2028\n    window = 2048\n    hop_length = train_duration*32000 // (img_size[1] - 1)\n    fmin = 20\n    fmax = 16000\n    normalize = True\n\n    # Data Preprocessing Settings\n    class_names = sorted(os.listdir('/kaggle/input/birdclef-2024/train_audio/'))\n    num_classes = len(class_names)\n    class_labels = list(range(num_classes))\n    label2name = dict(zip(class_labels, class_names))\n    name2label = {v:k for k,v in label2name.items()}\n    \n    target_col = ['target']\n    tab_cols = ['filename','common_name','rate']","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.876045Z","iopub.execute_input":"2024-06-06T03:04:23.876597Z","iopub.status.idle":"2024-06-06T03:04:23.895227Z","shell.execute_reply.started":"2024-06-06T03:04:23.876555Z","shell.execute_reply":"2024-06-06T03:04:23.89366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.896759Z","iopub.execute_input":"2024-06-06T03:04:23.897532Z","iopub.status.idle":"2024-06-06T03:04:23.971541Z","shell.execute_reply.started":"2024-06-06T03:04:23.897492Z","shell.execute_reply":"2024-06-06T03:04:23.968281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_device():\n    \"Detect and intializes GPU/TPU automatically\"\n    # Check TPU category\n    tpu = 'local' if CFG.device=='TPU-VM' else None\n    try:\n        # Connect to TPU\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=tpu) \n        # Set TPU strategy\n        strategy = tf.distribute.TPUStrategy(tpu)\n        print(f'> Running on {CFG.device} ', tpu.master(), end=' | ')\n        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n        device=CFG.device\n    except:\n        # If TPU is not available, detect GPUs\n        gpus = tf.config.list_logical_devices('GPU')\n        ngpu = len(gpus)\n         # Check number of GPUs\n        if ngpu:\n            # Set GPU strategy\n            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n            # Print GPU details\n            print(\"> Running on GPU\", end=' | ')\n            print(\"Num of GPUs: \", ngpu)\n            device='GPU'\n        else:\n            # If no GPUs are available, use CPU\n            print(\"> Running on CPU\")\n            strategy = tf.distribute.get_strategy()\n            device='CPU'\n    return strategy, device, tpu","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:23.978375Z","iopub.execute_input":"2024-06-06T03:04:23.978884Z","iopub.status.idle":"2024-06-06T03:04:23.994041Z","shell.execute_reply.started":"2024-06-06T03:04:23.97882Z","shell.execute_reply":"2024-06-06T03:04:23.992696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize GPU/TPU/TPU-VM\nstrategy, CFG.device, tpu = get_device()\nCFG.replicas = strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.003188Z","iopub.execute_input":"2024-06-06T03:04:24.003623Z","iopub.status.idle":"2024-06-06T03:04:24.015796Z","shell.execute_reply.started":"2024-06-06T03:04:24.00359Z","shell.execute_reply":"2024-06-06T03:04:24.014445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/birdclef-2024'\nGCS_PATH = BASE_PATH","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.01764Z","iopub.execute_input":"2024-06-06T03:04:24.01815Z","iopub.status.idle":"2024-06-06T03:04:24.032121Z","shell.execute_reply.started":"2024-06-06T03:04:24.018106Z","shell.execute_reply":"2024-06-06T03:04:24.030479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_audio_dir = '/kaggle/input/birdclef-2024/test_soundscapes/'\n\ntest_paths = [test_audio_dir+f for f in sorted(os.listdir(test_audio_dir))]\nif len(test_paths)==1:\n    test_audio_dir = '/kaggle/input/birdclef-2024/unlabeled_soundscapes/'\n\n    test_paths = [test_audio_dir+f for f in sorted(os.listdir(test_audio_dir))][:2]\n    \ntest_df = pd.DataFrame(test_paths, columns=['filepath'])\ntest_df['filename'] = test_df.filepath.map(lambda x: x.split('/')[-1].replace('.ogg',''))\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.034181Z","iopub.execute_input":"2024-06-06T03:04:24.035509Z","iopub.status.idle":"2024-06-06T03:04:24.069309Z","shell.execute_reply.started":"2024-06-06T03:04:24.035462Z","shell.execute_reply":"2024-06-06T03:04:24.067795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.io.gfile.exists(test_df.filepath.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.071458Z","iopub.execute_input":"2024-06-06T03:04:24.071999Z","iopub.status.idle":"2024-06-06T03:04:24.081755Z","shell.execute_reply.started":"2024-06-06T03:04:24.071956Z","shell.execute_reply":"2024-06-06T03:04:24.080407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_audio(filepath, sr=32000, normalize=True):\n    audio, orig_sr = librosa.load(filepath, sr=None)\n    if sr!=orig_sr:\n        audio = librosa.resample(y, orig_sr, sr)\n    audio = audio.astype('float32').ravel()\n    audio = tf.convert_to_tensor(audio)\n    return audio\n\n@tf.function(jit_compile=True)\ndef MakeFrame(audio, duration=5, sr=32000):\n    frame_length = int(duration * sr)\n    frame_step = int(duration * sr)\n    chunks = tf.signal.frame(audio, frame_length, frame_step, pad_end=True)\n    return chunks","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.083696Z","iopub.execute_input":"2024-06-06T03:04:24.084157Z","iopub.status.idle":"2024-06-06T03:04:24.096993Z","shell.execute_reply.started":"2024-06-06T03:04:24.084124Z","shell.execute_reply":"2024-06-06T03:04:24.095596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_audio(row):\n    # Caption for viz\n    caption = f'Id: {row.filename}'\n    # Read audio file\n    audio = load_audio(row.filepath)\n    # Keep fixed length audio\n    audio = audio[:CFG.audio_len]\n    # Display audio\n    print(\"# Audio:\")\n    display(ipd.Audio(audio.numpy(), rate=CFG.sample_rate))\n    print('# Visualization:')\n    plt.figure(figsize=(12, 3))\n    plt.title(caption)\n    # Waveplot\n    lid.waveshow(audio.numpy(),\n                 sr=CFG.sample_rate,)\n                 \n    plt.xlabel('');\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.099953Z","iopub.execute_input":"2024-06-06T03:04:24.100615Z","iopub.status.idle":"2024-06-06T03:04:24.114742Z","shell.execute_reply.started":"2024-06-06T03:04:24.100572Z","shell.execute_reply":"2024-06-06T03:04:24.113534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display_audio(test_df.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.116782Z","iopub.execute_input":"2024-06-06T03:04:24.117249Z","iopub.status.idle":"2024-06-06T03:04:24.125743Z","shell.execute_reply.started":"2024-06-06T03:04:24.117209Z","shell.execute_reply":"2024-06-06T03:04:24.124329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n# Directory of checkpoint\nCKPT_DIR = '/kaggle/input/birdclef2024training'\n\n# Get file paths of all trained models in the directory\nCKPT_PATHS = sorted([x for x in glob(f'{CKPT_DIR}/fold-*keras')])\nprint(\"Checkpoints: \", CKPT_PATHS)\n\n\n# Define a writable directory\nWRITABLE_DIR = '/kaggle/working/models/'\n\n# Create the writable directory if it does not exist\nif not os.path.exists(WRITABLE_DIR):\n    os.makedirs(WRITABLE_DIR)\n\n\n# Copy the model files to the writable directory\nfor ckpt_path in CKPT_PATHS:\n    shutil.copy(ckpt_path, WRITABLE_DIR)\n\n# Update the checkpoint paths to the writable directory\nCKPT_PATHS = sorted([f'{WRITABLE_DIR}/{os.path.basename(x)}' for x in glob(f'{CKPT_DIR}/fold-*keras')])\n\n# Load all the models in memory to speed up\nCKPTS = [tf.keras.models.load_model(x, compile=False) for x in tqdm(CKPT_PATHS, desc=\"Loading ckpts \")]\n# Num of ckpt to use\nNUM_CKPTS = 1\n\n# Submit or Interactive mode\n#SUBMIT = pd.read_csv('/kaggle/input/birdclef-2024/sample_submission.csv').shape[0] != 3","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:24.127595Z","iopub.execute_input":"2024-06-06T03:04:24.128067Z","iopub.status.idle":"2024-06-06T03:04:30.5591Z","shell.execute_reply.started":"2024-06-06T03:04:24.128035Z","shell.execute_reply":"2024-06-06T03:04:30.557683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start stopwatch\ntick = time.time()\n\n# Initialize empty list to store ids\nids = []\n# Initialize empty array to store predictions\npreds = np.empty(shape=(0, 182), dtype='float32')\n\n# Iterate over each audio file in the test dataset\nfor filepath in tqdm(test_df.filepath.tolist(), 'test '):\n    # Extract the filename without the extension\n    filename = filepath.split('/')[-1].replace('.ogg','')\n    \n    # Load audio from file and create audio frames, each recording will be a batch input\n    audio = load_audio(filepath)\n    chunks = MakeFrame(audio)\n    \n    # Predict bird species for all frames in a recording using all trained models\n    chunk_preds = np.zeros(shape=(len(chunks), 182), dtype=np.float32)\n    for model in CKPTS[:NUM_CKPTS]:\n        # Get the model's predictions for the current audio frames\n        rec_preds = model(chunks, training=False).numpy()\n        # Ensemble all prediction with average\n        chunk_preds += rec_preds/len(CKPTS)\n    \n    # Create a ID for each frame in a recording using the filename and frame number\n    rec_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(chunks))]\n    \n    # Concatenate the ids\n    ids += rec_ids\n    # Concatenate the predictions\n    preds = np.concatenate([preds, chunk_preds], axis=0)\n    \n# Stop stopwatch\ntock = time.time()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:30.561633Z","iopub.execute_input":"2024-06-06T03:04:30.562327Z","iopub.status.idle":"2024-06-06T03:04:37.045852Z","shell.execute_reply.started":"2024-06-06T03:04:30.562281Z","shell.execute_reply":"2024-06-06T03:04:37.044727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.047795Z","iopub.execute_input":"2024-06-06T03:04:37.048213Z","iopub.status.idle":"2024-06-06T03:04:37.056069Z","shell.execute_reply.started":"2024-06-06T03:04:37.04818Z","shell.execute_reply":"2024-06-06T03:04:37.054545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit prediction\npred_df = pd.DataFrame(ids, columns=['row_id'])\npred_df.loc[:, CFG.class_names] = preds\npred_df.to_csv('submission2.csv',index=False)\npred_df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.057817Z","iopub.execute_input":"2024-06-06T03:04:37.058303Z","iopub.status.idle":"2024-06-06T03:04:37.260903Z","shell.execute_reply.started":"2024-06-06T03:04:37.058259Z","shell.execute_reply":"2024-06-06T03:04:37.259556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ÂêàÂπ∂Êï∞ÊçÆ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# ËØªÂèñ‰∏§‰∏™CSVÊñá‰ª∂\ndf1 = pd.read_csv('/kaggle/working/submission1.csv')\ndf2 = pd.read_csv('/kaggle/working/submission2.csv')\n\n# ËÆ°ÁÆóÊñ∞ÁöÑÊï∞ÊçÆÊ°ÜÔºàÊéíÈô§Ë°®Â§¥Ôºâ\nnew_df = df1.iloc[:, 1:] * 0.8 + df2.iloc[:, 1:] * 0.2\n\n# Â∞ÜË°®Â§¥ÈáçÊñ∞Âä†ÂÖ•Êñ∞ÁöÑÊï∞ÊçÆÊ°Ü\nnew_df.insert(0, df1.columns[0], df1[df1.columns[0]])\n\n# ‰øùÂ≠òÊñ∞ÁöÑÊï∞ÊçÆÊ°ÜÂà∞CSVÊñá‰ª∂\nnew_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.372588Z","iopub.execute_input":"2024-06-06T03:04:37.372972Z","iopub.status.idle":"2024-06-06T03:04:37.409119Z","shell.execute_reply.started":"2024-06-06T03:04:37.37294Z","shell.execute_reply":"2024-06-06T03:04:37.407778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_time = (tock-tick)*550 # ~1100 recording on the test data\n# sub_time = time.gmtime(sub_time)\n# sub_time = time.strftime(\"%H hr: %M min : %S sec\", sub_time)\n# print(f\">> Time for submission: ~ {sub_time}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:04:37.505683Z","iopub.status.idle":"2024-06-06T03:04:37.50617Z","shell.execute_reply.started":"2024-06-06T03:04:37.50596Z","shell.execute_reply":"2024-06-06T03:04:37.505979Z"},"trusted":true},"execution_count":null,"outputs":[]}]}